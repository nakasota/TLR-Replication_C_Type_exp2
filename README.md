# TLR-Replication C-type

設計書と C リポジトリのリンク生成ワークフローです。

---

## プロジェクト概要

### 実験目的

**仕様に対する成果物のトレーサビリティ**をとることを目的とします。

### 概要

仕様の一節を与えると、コードリポジトリ内の複数のコード（ディレクトリ・ファイル・関数）がそれに対応します。本ツールは、**その対応するディレクトリ・ファイル・関数を特定する**ことを目的とします。LLM を用いて設計書（仕様）の各節と、C ソースコードのどの位置が紐づくかを推定し、リンクとして出力します。

### 入力

- **仕様の 1 節**  
  - Markdown（`.md`）形式の設計書。1 ファイルが仕様の一節に対応する想定です。
- **コード**  
  - ディレクトリ構造をもった C プロジェクト。数百 MB 規模のリポジトリを想定しています。  
  - **今回の対象は `.c` と `.h` に限定しています。** リポジトリ内のそれ以外のファイル（例: `.txt`, `.md`, 設定ファイルなど）はフィルタリングされ、リンク対象には含まれません。

---

## 前提条件

本ツールを実行するために必要な環境です。

- **Python**  
  - Python 3.x を想定しています。推奨は 3.8 以上です。
- **依存パッケージ**  
  - `requirements.txt` に記載のパッケージをインストールしてください（後述のセットアップで `pip install -r requirements.txt` を実行します）。
- **LLM API キー**  
  - チャット補完に **DeepSeek** または **Microsoft Azure OpenAI** のいずれかを使用します。いずれかに対応する API キーを用意し、後述のとおり環境変数または `.env` で設定してください。

---

## セットアップ

### ライブラリのインストール

プロジェクトルートで次を実行してください。

```bash
pip install -r requirements.txt
```

### .env の作成と API キー

LLM のチャット補完には API キーが必要です。プロジェクトルートに `.env` を作成し、使用するプロバイダに応じて次のいずれかを設定してください。

- **DeepSeek を使う場合**  
  - `DEEPSEEK_API_KEY=あなたのAPIキー` を `.env` に記載してください。
- **Microsoft Azure OpenAI を使う場合**  
  - `AZURE_OPENAI_ENDPOINT`（例: `https://YOUR_RESOURCE.openai.azure.com`）  
  - `AZURE_OPENAI_API_KEY`  
  - `AZURE_OPENAI_DEPLOYMENT`（デプロイ名）  
  の 3 つを `.env` に記載してください。  
  - 詳細は後述の「LLM API」を参照してください。

### データセットの配置と形式

ワークフローは `data/` 以下の設計書と C リポジトリを参照します。実行前に次のように配置してください。

- **C リポジトリ**  
  - `data/repos/{名前}/` に、C プロジェクトを**そのまま**配置してください。  
  - 例: `data/repos/sample_repo/` や `data/repos/sample_repo_1/`。ディレクトリ構造や `.c`・`.h` などのファイルは、元のリポジトリのままにしてかまいません。

- **設計書（仕様）**  
  - `data/docs/{名前}/` に、Markdown（`.md`）形式の設計書を配置してください。  
  - **リンクさせたい粒度に合わせて 1 ファイルに分けてください。** 例えば「1 節＝1 ファイル」とする場合、仕様の 1 節ごとに 1 つの `.md` ファイルを作成し、それらを同じディレクトリに置きます。  
  - 例: `data/docs/sample_doc/` に `overview.md`, `api_logger.md`, `api_math_utils.md` のように、節やトピックごとの `.md` を並べます。  
  - ワークフローは「1 ファイル ＝ 仕様の 1 単位」として、その単位とコードのディレクトリ・ファイル・関数の対応を推定します。

---

## 使い方（対話モード）

`src` ディレクトリに移動し、次を実行するとワークフローが起動します。

```bash
cd src
python coordinated_workflow.py
```

起動後、対話形式で次の項目を入力します。括弧内はデフォルト値です。

### 起動時に選択する項目

1. **設計書セット（DOCS_SET）**  
   - 使用する設計書のセットを選びます。`data/docs/` の下にあるディレクトリ名のいずれかを指定します。  
   - 例: `sample_doc`, `sample_doc_1`。  
   - 未入力の場合は表示されているデフォルト（例: `sample_doc`）が使われます。

2. **リポジトリ（REPO_SET）**  
   - 対象とする C リポジトリを選びます。`data/repos/` の下にあるディレクトリ名のいずれかを指定します。  
   - 例: `sample_repo`, `sample_repo_1`。  
   - 未入力の場合は表示されているデフォルト（例: `sample_repo`）が使われます。

3. **リポジトリ構造タイプ（プロンプトのサイズ）**  
   - LLM に渡す「リポジトリ構造」の長さを決めます。`full`, `500`, `1000`, `2000` のいずれかです。  
   - 数値は **1 チャンクあたりの最大行数**を表します（例: `500` は 500 行、`2000` は 2000 行）。`full` は分割せず全体を 1 チャンクにします。  
   - **`full` や `2000`** にすると、リポジトリを少ないチャンクにまとめるため **API 呼び出し回数が減り、全体の実行時間は短くなりがち**です。  
   - 一方で、**プロンプトが長くなる**ため、LLM の精度が落ちたり、モデルのコンテキストウィンドウに収まらなくなる可能性があります。  
   - **`500` や `1000`** にすると、プロンプトは短くなりコンテキストに収まりやすくなりますが、チャンク数が増え、実行時間は長くなりがちです。  
   - リポジトリの規模や使用するモデルのコンテキスト長に応じて、**適宜調節してください**。未入力の場合は `2000` が使われます。

4. **バッチサイズ**  
   - 今回の実行で処理する設計書の数を指定します。  
   - 数値（例: `5`, `10`）を入力するとその件数だけ処理し、`all` を入力すると全設計書を処理します。未入力の場合は `all` になります。

5. **開始位置（Start from index）**  
   - 何件目から処理を始めるか、0 始まりのインデックスで指定します。  
   - 例: `0` で先頭から、`3` で 4 件目から。未入力の場合は `0` になります。

---

## ワークフローの流れ

ワークフロー全体の流れは次のとおりです。全体図は [assets/workflow.pdf](assets/workflow.pdf) を参照してください。

1. **Phase 0：粒度決定（Granularity Decision）**  
   - 各設計書（仕様の 1 節）について、コードとの対応を **ディレクトリ・ファイル・関数** のどの粒度で紐づけるかを LLM に判定させます。  
   - 出力: 設計書ごとに `directory` / `file` / `function` のいずれかが決まります。

2. **Phase 1：ローカライズ（Localization）**  
   - 粒度に応じて、対応するコードの候補を列挙します。  
   - **STEP 1 ディレクトリレベル**  
     - 粒度が「ディレクトリ」の設計書について、リポジトリ構造から該当しそうなディレクトリを LLM に選ばせます。  
   - **STEP 2 ディレクトリ＋ファイルレベル**  
     - 粒度が「ファイル」または「関数」の設計書について、該当しそうなファイルを LLM に選ばせます。リポジトリ構造（チャンク）をプロンプトに含めて候補ファイルを出します。  
   - **STEP 3 ファイルレベルリンク決定**  
     - STEP 2 で得たファイル候補のうち、設計書と「対応する」かどうかを LLM に Yes/No で判定させます。  
   - **STEP 4 関数レベルローカライズ**  
     - 粒度が「関数」の設計書について、候補ファイル内のどの関数が設計書と対応するかを LLM に選ばせます。

3. **Phase 2：関数レベルリンク決定（Function Level Link Decision）**  
   - STEP 4 で得た関数候補のうち、設計書と「対応する」かどうかを LLM に Yes/No で判定させます。

4. **最終：結果統合（Result Integration）**  
   - 上記の結果をまとめ、`src/output/{timestamp}/` に JSON・CSV・サマリレポートを出力します。

---

## 目視評価の仕方

手法を評価するとき、評価すべきことは次の 2 点です。

- **(1) リンクするべきコードの正しい粒度を選択できたか**  
  各ドキュメントについて、手法が「ディレクトリ・ファイル・関数」のうち正しい粒度を選べているか。
- **(2) その粒度で正しいリンクを生成できたか**  
  選んだ粒度において、正しいコードの場所（ディレクトリ／ファイル／関数）をリンクとして出せているか。

以下に、目視評価の **2 つの方針** を示します。

### 方針 1：(2) を Precision・Recall で評価する

**行うべきこと**

- 各ドキュメントに対して、**リンクするべきコードの粒度**を定義する（正解粒度）。
- 各ドキュメントに対して、**リンクするべきコードの場所**（ディレクトリ／ファイル／関数）を過不足なく定義する。
- 上記をもとに、各ドキュメントについて「粒度」と「場所」の **正解データ** を作成する。
- 手法の出力と正解を比較し、Precision と Recall を計算する。

**メリット**  
包括的な評価が可能である。

**デメリット**  
各ドキュメントに対してリンクするべきコードの位置を過不足なく定義するのが現実的に可能かどうかは場合による。工数がかかる。

---

### 方針 2：(1) を Precision のみで評価する（MSR 2026 論文で採用された方式）

**行うべきこと**

- 各ドキュメントに対して、**リンクするべきコードの粒度**を定義する（正解粒度）。
- 各ドキュメントに対して、**手法が出力したリンクが正しいかどうか**を判定する（正解の「場所」の一覧は作らず、生成されたリンクごとに正誤を付ける）。
- 上記をもとに、各ドキュメントについて **粒度の正解データ** を作成し、生成されたリンクの正誤判定を行う。  
  これにより **Precision のみ** を評価する（Recall を求めるには正解の「場所」の一覧が必要なため、この方針では評価しない）。

**メリット**  
正解粒度の定義とリンクの正誤判定だけでよいため、実現可能性が高い。方針 1 に比べて工数は小さい。

**デメリット**  
粒度選択とリンクの正しさの一部（Precision）しか評価できず、手法の部分的な評価にとどまる。

