=== Fetching Proposal: MDU6SXNzdWU0NjA2NDM2MTk= ===
Issue URL: https://github.com/golang/go/issues/32779

==== [Issue Title] ====
encoding/json: memoize strings during decode

==== [Issue Body] ====
Part of the motivation for #32593 is the observation in json-iterator/go#376 that when you json decode, many of the same strings appear over and over in the JSON and get copied and reconstructed in the result over and over as well. 

We do _not_ want to make the JSON coalesce all the allocated strings into one giant buffer, because then holding on to just one of them holds onto the entire thing.

But it might make sense to add to the decoder state a simple map[[]byte]string and remember which specific byte slices we've already converted to string and reuse those allocated strings instead of doing the same conversions again in a particular Decode or Unmarshal operation. 

It's unclear to me whether the map in a Decoder should persist between Decode operations. Probably? That will affect users who put Decoders in a pool or something like that, though. (Solution: don't put decoders in pools.)

==== [Comments] ====

--- Comment #1 by bserdar ---
A while ago I wrote some code to test this exact same thing with the json decoder, but could not detect any significant difference between the memory usage of the decoder with memoized strings and the regular json decoder, which made me think maybe this is already done somewhere? Apparently not. I can try to find out my test code...

--- Comment #2 by bserdar ---
Here's a link to my test code that does this for decoding json into interface{}:

https://github.com/bserdar/jsdecodertest

My initial comment was wrong, it does make a difference to store strings in a map. My test code stores only field keys in a map because those are the strings that are likely to repeat. 

The json/ package is a copy of the stdlib encoding/json package modified to include a map[string]string in the decoder state.

--- Comment #3 by martisch ---
Nit: I assume the proposal meant to use a `map[string]string` with `map[string([]byte)]` lookup as `map[[]byte]string` is not a supported map type.

--- Comment #4 by mvdan ---
Also cc @josharian, who had a very similar idea a while ago. That was briefly discussed in #5160.

As a thought, we probably don't want to reuse all strings. For example, in a map the keys probably tend to repeat much more often than the values.

Also, do we want to make this configurable? Someone who writes a program likely knows whether they'll read somewhat static/repeated data or not.

--- Comment #5 by gopherbot ---
Change https://golang.org/cl/188500 mentions this issue: `encoding/json: memoize keys during decode`

--- Comment #6 by rsc ---
@mvdan, are you concerned about the overhead of the map lookup in your Jun 26 comment? From the outside there can be no possible downside to reusing all strings that are constructed.


--- Comment #7 by bserdar ---
The CL mentioned above has an implementation of this for JSON decoder. It introduces some overhead when decoding to an interface{}, because that's the only case where the keys read during decoding will be kept after decoding is done.

However, I think there is a better way to do this. What I propose is to write an encoding/LiteralStore type (a map[string]string) containing a Get(string) string method to retrieve the shared instance of the string. Then this can be used from the decoders in encoding/xml and encoding/json. To use the LiteralStore, the caller has to assign an instance to the JSON/XML decoder. This way, the caller has the option to use a literal store for large input where it makes a difference, use the store for multiple docs, or avoid it completely.

What do you think?



--- Comment #8 by bcmills ---
This is one of the conventional use-cases for weak references in GC'd languages.

Ideally, we should reuse strings that remain reachable from the last `Decode` invocation, and let the collector clean up any strings that have since become completely unreachable. That way, the frequently-used strings will remain in the map, but the infrequent strings can still be collected (so that the map doesn't grow without bound if the same Decoder is used on many different inputs over time).

--- Comment #9 by bcmills ---
Alternatives that do not require weak references include:
* Make the interning behavior an explicit opt-in using a `Decoder` method (perhaps `func (*Decoder) InternStrings(func([]byte)bool)`).
* Make the interning behavior an explicit annotation on the struct field tag.
   * But this gets awkward to describe the behavior for map keys vs. map values.

--- Comment #10 by bserdar ---
@bcmills, I propose to make the interning behavior explicit opt-in using a `Decoder` field instead of a method. After reading #32593, I believe one way to make this acceptable in terms of performance and usage is this:

 * Add a strings/LiteralStore type (a map[string]string), with an Add(string) string method that will return a shared copy for string
 * Add `Decoder.KeyLiterals` field of type LiteralStore to both json and xml decoders.
 * Use the `KeyLiterals` if it is non-nil during decoding to store keys 

This implementation does not change the existing behavior and makes the use of a literal store explicit opt-in. 

A literal store like this is only useful for larger json/xml input, and only if it is manually decoded, or unmarshaled into an interface{}. If the input is unmarshaled/decoded into a struct, then there is no need to keep the keys as they will be lost. 

Re: weak references, afaik there is no way to implement this using finalizers, am I wrong?

--- Comment #11 by ianlancetaylor ---
@bserdar I don't think there is any way to do this with finalizers because existing users will be using `string` values, not pointers, so there is nothing to hang a finalizer on.  For that matter weak references wouldn't work either: you would have to change all the users to use the weak reference type rather than `string`.

In general finalizers and weak references are equivalent in power, so anything you can do with one you can do with the other.  But you have to be able to control the types that people will use.

--- Comment #12 by bserdar ---
@ianlancetaylor thanks for the clarification.

If there is interest in this, I can modify https://golang.org/cl/188500 to implement this. I already have some wrapper code around json/xml decoder to do this because reusing just the key strings makes a lot of difference for large docs.

cc @mvdan 

--- Comment #13 by bcmills ---
> For that matter weak references wouldn't work either: you would have to change all the users to use the weak reference type rather than `string`.

No? We would need some sort of language-supported “weak string” type, but then only the `json.Decoder` would hold a weak reference — the decoded messages would use a regular `string` so that the data doesn't disappear out from beneath them.

(But that assumes a language change that seems pretty unlikely to ever happen.)

--- Comment #14 by bcmills ---
> In general finalizers and weak references are equivalent in power, so anything you can do with one you can do with the other. But you have to be able to control the types that people will use.

Ah, I think I see what you're saying. If we could control the types in use, then we could add a pointer indirection, and require users to keep the pointer alive in order to retain the `string` value in the decoder's cache.

But then you can't use those pointers in the same way as ordinary strings: they can't be map keys, they won't work with the normal built-in `string` operations, and they can't be passed to the `strings` package without falling back to manual memory management (via `runtime.KeepAlive`).

It may be true that they are _technically_ equivalent in power, but they are not equivalently usable.

--- Comment #15 by bcmills ---
@bserdar, `strings.LiteralStore` seems unfortunate given that we're also discussing adding generics to the language, because there is a much more general “interning table” API that can be used with any type that supports hashing and equality.

The general form could have an API like:
```go
package intern

type Table(type T HashEqualer) […]

func (t Table(T)) Get(x T) (canonicalX T) {
	[…]
}
```

Such an API is also useful for building things like abstract syntax trees, where it can be useful to compress trees by coalescing occurrences of a common subexpression to the same canonical instance.

(A long time ago I maintained a server that evaluated large numbers of boolean expressions for ad targeting, and it used a similar approach — to great effect — to compress the targeting expressions, including in our wire protocol.)

--- Comment #16 by bserdar ---
@bcmills, interning table would be nice, but it won't be available any time soon. Until that becomes available, we can keep interning internal to the Decoder, but expose an InternKeys(bool) method for explicit opt-in. Or, implement the strings.LiteralStore, and change it to use the intern package when generics are done.

--- Comment #17 by bserdar ---
xml.Decoder can benefit from interning strings as well. What is the opinion about that?  Decoder.InternKeys() would be the explicit opt-in for interning keys during decode. Something similar to this: https://go-review.googlesource.com/c/go/+/188500


--- Comment #18 by rsc ---
There's been a lot of discussion here but I haven't seen any objections to simply putting the map I suggested into Decoder and not trying to reuse it any more than that. 

I've seen no rationale for adding new API. Just do it all the time. Am I missing something?



--- Comment #19 by bserdar ---
There is a small performance hit it if it used all the time. Measurements are here: https://go-review.googlesource.com/c/go/+/188500:

CodeDecoder-8                         9.87ms ± 2%
CodeDecodeToInterfaceNoIntern-8       10.9ms ± 3%
CodeDecodeToInterfaceIntern-8         11.6ms ± 4%

If there is interest in this, I can fix that CL

--- Comment #20 by rsc ---
I'd gladly take that performance hit over new API. Most JSON has many repeated strings so as long as we can show a lowered memory usage I think that's a clear win.



--- Comment #21 by bserdar ---
It uses less memory with interning. These are from the same unit test (CodeDecode*), with explicit calls to gc:

No interning:

Alloc:10708232 TotalAlloc:26603840 Sys:71762168 Lookups:0 Mallocs:364454 Frees:196341 HeapAlloc:10708232 HeapSys:66519040 HeapIdle:54239232 HeapInuse:12279808 HeapReleased:49496064 HeapObjects:168113

With interning:

Alloc:10487800 TotalAlloc:38961736 Sys:71762168 Lookups:0 Mallocs:635980 Frees:481644 HeapAlloc:10487800 HeapSys:66617344 HeapIdle:52895744 HeapInuse:13721600 HeapReleased:44720128 HeapObjects:154336

--- Comment #22 by rsc ---
This seems worth doing, and it seems like a minor optimization, not a visible API change. 
It's unclear this really needs to be in the proposal process at all,
but since it's here, based on the discussion above and how little is affected,
it seems like a **likely accept**.


--- Comment #23 by mvrhov ---
I'd say that the memory comments are the other way around?

--- Comment #24 by rsc ---
@mvrhov, sorry, I don't quite understand what you mean.


--- Comment #25 by mvrhov ---
Well the numbers for interned strings are larger... Total allocs by 30%, the number of mallcos by 50%, frees by 60%. The number of allcos is smaller by 2%

--- Comment #26 by bserdar ---
Allocs are smaller meaning there's less memory allocated in the end. TotalAlloc is higher because of the interning. Frees are larger, because most of the interned string copies that would've been in the unmarshaled object are collected. Overall, with interning when everything is said and done, there's less memory allocated.

--- Comment #27 by mvdan ---
> @mvdan, are you concerned about the overhead of the map lookup in your Jun 26 comment? From the outside there can be no possible downside to reusing all strings that are constructed.

@rsc sorry that I missed your comment for this long. I could have sworn I had replied.

My concern is about keeping strings alive for longer than needed. That's very much related to one of your original points:

> It's unclear to me whether the map in a Decoder should persist between Decode operations. Probably?

For example, imagine if I have a server that receives JSON objects via a network stream, unmarshals them, writes them to a database, and discards them. Right now, I would write this program in a way that the "incoming objects" goroutine keeps a single decoder alive forever.

If the decoder starts memoizing strings forever (since the decoder persists forever), my memory usage could increase over time if I keep seeing new/unique strings. For example, it seems pretty common to represent UUIDs and hashes as strings in JSON, so I'm a bit worried that users could easily run into this kind of "memory leak".

--- Comment #28 by bserdar ---
@mvdan, is this still a concern if only the JSON keys are memoized? Keys are repetitive. The memory numbers I pasted a while ago above is from memoizing only the JSON keys, not the field values.

Also, memoizing keys are only meaningful when decoding to a map. 

--- Comment #29 by mvdan ---
It's unclear to me if the current proposal is to memoize all strings, or just keys when decoding into `map[string]T`. I imagine most cases of unique/changing strings don't happen in map keys, but I still find that a possible scenario. For example, a map where the keys are unique IDs or hashes seems pretty reasonable, if one wants to then do quick lookups after unmarshaling.

So, my concern is probably smaller if we only memoize map keys, but even then, I'm still a bit concerned.

--- Comment #30 by rsc ---
The proposal is to only memoize in a single json.Decoder, not globally.
If you want to avoid the memoization, you could use multiple json.Decoders.
Note that each call to json.Unmarshal uses its own Decoder, so all those would be independent.
(If you decoded an object list into a []map[string]int, then all the map keys in one decoding could be shared, but not across decodings.)

Another possibility is to do the memoization by default but allow a hook in the Decoder (a method `SetSaveString(func([]byte) string)` or something like that) that would let you override the policy to have a global pool, or a pool only for small strings. 

But it seems like we if there's a win-win here then we should take that win by default.

Does anyone object to marking this accepted assuming that there is a win-win?
Obviously if the benchmarks say there isn't a win then we wouldn't take the CL.
