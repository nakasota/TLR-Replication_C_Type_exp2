==== [Issue Title] ====
reflect: add Value.SetZero

==== [Issue Body] ====
This is a re-proposal of #33136, which was converted into a performance optimization where `reflect.Zero` does not allocate. That change certainly helps, but is insufficient especially when trying to zero out small values.

I propose we add a dedicated `Value.SetZero` method.

A prototype implementation of mine shows that this is much faster for small values:
```
Bool:       3.9x faster
Int:        3.5x faster
Uint:       3.9x faster
Float:      3.6x faster
Pointer:    2.2x faster
Map:        2.3x faster
Slice:      3.1x faster
Interface:  1.7x faster
String:     3.3x faster
```

Unfortunately, there is no convenient `SetXXX` API for clearing nil-able types (e.g., pointers, slices, and maps) and I was going to propose a `Value.SetNil` method, but we might as well expand that handle clearing all kinds.

==== [Comments] ====

--- Comment #1 by ianlancetaylor ---
CC @randall77 

--- Comment #2 by randall77 ---
Seems fine to me.


--- Comment #3 by AAlvarez90 ---
@dsnet Are you going to try to tackle this for 1.19?

--- Comment #4 by zaunist ---
`Value.SetZero`ã€`Value.SetNil` method and the corresponding test case need to be added, right? If that's all, I'm happy to do it :)

--- Comment #5 by AAlvarez90 ---
@zaunist It is a start but I think @dsnet may have something else planned. Anyways. Any safe performance improvement is always welcome.

--- Comment #6 by dsnet ---
> @dsnet Are you going to try to tackle this for 1.19?

I have an implementation ready, but this needs to go through the proposal process. There is no guarantee that this gets accepted.  

--- Comment #7 by AAlvarez90 ---
@randall77 , @ianlancetaylor  what would be the next step to make this happen?

--- Comment #8 by randall77 ---
It will be looked at by the proposal committee. If you have arguments in favor (existing code which would be made cleaner/faster/whatever) please post them here.
Probably it will not make the freeze for 1.19, which I believe is in 2 weeks.


--- Comment #9 by ianlancetaylor ---
The proposal process is explained at https://go.dev/s/proposal-process.

--- Comment #10 by AAlvarez90 ---
@randall77 , @ianlancetaylor, @rsc   Forgive my ignorance in this matter as I am still finding my way around the Go community, ecosystem and looking for ways to collaborate, but I have the feeling the following 2 feelings which I would like to just flush out and for lack knowledge about the appropriate channels I will just post them here.
1. As we speak, there are about 525 open issues labeled `Performance`. If at least 400 of them came out to be valid, having them merged would definitely make Go execute faster in many many tasks. It feels that performance optimizations to the language are dreaded and other changes are preferred. According to the latest survey, 25% of the people that preferred another language over Go ended up going for Rust. I have been in Rust forums and I have seen a lot of people talking about the critical speed that Rust offered over Go, etc.. Now Go is way more pleasurable to write than Rust, we get to build something usable faster and many other benefits. But what if we had a "Performance" sprint to get as many of these optimizations in and get Go to execute much faster so there is a point in which the adoption of Rust over Go because of runtime execution time is not longer even considered. Again, apologies for my ignorance. My opinion is based on multiple comments I have seen in their community Discord channels across the past 12 months.
2. The entire proposal - Go release feels slow. Currently there are 2 major version release every year. But what if there could be 4 release per year? 2 major version, 2 small version releases. In the small version releases we could sneak in changes like this one which would not be a huge language change? Then during the proposal meetings there could be a filtering between issues that would go in the major/minor releases. I understand that we currently do those stability releases after the "major" release but those are pretty much meant to fix issues that may have come up after the big release. At the current speed it could take easily 4 years to drain the issues pipeline. I have looked around and there are just a few names that always come up including yours. This is a lot of work, a lot of things going on and only a few people that can look at them and potentially have a final say. In mean, in those weekly proposal meetings, how many issues can you guys look into anyways?
Please, let me know when you have a change what you think of this.

--- Comment #11 by mvdan ---
@AAlvarez90 this is starting to get off-topic - I would suggest that you summarize your points and send an email to https://groups.google.com/g/golang-dev.

But as a general rule of thumb, increasing the amount of releases or changing the priorities of the team won't magically make features and improvements get implemented faster. You still have the same amount of people working full-time either way. And yes, performance is relevant, but it's not the only important objective for Go - and even 500 issues are a minority when compared to the 7k+ open in total.

--- Comment #12 by rsc ---

This proposal has been added to the [active column](https://golang.org/s/proposal-status#active) of the proposals project
and will now be reviewed at the weekly proposal review meetings.
â€” rsc for the proposal review group


--- Comment #13 by rsc ---
@dsnet, can you confirm that you are comparing with the v.Set(reflect.Zero(v.Type())) that has been optimized as in #33136 and that that expression is not allocating?

Assuming yes, then adding SetZero for the final 2-4X seems OK.



--- Comment #14 by gopherbot ---
Change https://go.dev/cl/411476 mentions this issue: `reflect: add Value.SetZero`

--- Comment #15 by dsnet ---
Given that #33136 has been around since Go1.16, I'm fairly sure I'm accounting from the benefits of that optimization.

In https://go.dev/cl/411476, the performance numbers are as follows:

                         Direct         CachedZero     NewZero
    SetZero/Bool         2.20ns Â± 0%    8.97ns Â± 5%    11.4ns Â± 1%
    SetZero/Int          3.08ns Â± 1%    9.06ns Â± 1%    11.5ns Â± 0%
    SetZero/Uint         2.88ns Â± 1%    9.04ns Â± 1%    11.7ns Â± 5%
    SetZero/Float        2.65ns Â± 2%    9.05ns Â± 1%    11.5ns Â± 1%
    SetZero/Complex      2.68ns Â± 3%    9.31ns Â± 1%    11.7ns Â± 1%
    SetZero/Array        6.69ns Â± 4%    9.32ns Â± 1%    11.8ns Â± 1%
    SetZero/Chan         3.31ns Â± 1%    6.19ns Â± 1%    8.20ns Â± 1%
    SetZero/Func         3.32ns Â± 1%    6.20ns Â± 0%    8.24ns Â± 1%
    SetZero/Any          2.64ns Â± 1%    9.39ns Â± 3%    11.8ns Â± 2%
    SetZero/Interface    2.66ns Â± 1%    9.31ns Â± 1%    11.8ns Â± 1%
    SetZero/Map          3.31ns Â± 1%    6.21ns Â± 2%    8.19ns Â± 1%
    SetZero/Pointer      3.30ns Â± 1%    6.22ns Â± 1%    8.17ns Â± 1%
    SetZero/Slice        2.90ns Â± 4%    9.13ns Â± 1%    11.6ns Â± 1%
    SetZero/String       3.11ns Â± 1%    9.30ns Â± 1%    11.8ns Â± 2%
    SetZero/Struct       6.37ns Â± 1%    9.18ns Â± 4%    11.5ns Â± 1%

where:
* `Direct` is the performance of `v.SetZero()`
* `CachedZero` is the performance of `v.Set(zero)` where `zero` is a pre-computed variable with `Zero(v.Type())`
* `NewZero` is the performance of `v.Set(Zero(v.Type()))`

we can see that `Direct` is generally 2-4x faster.

--- Comment #16 by rsc ---
Thanks for the numbers. This seems fine now that we understand the justification well.


--- Comment #17 by rsc ---

Based on the discussion above, this proposal seems like a **[likely accept](https://golang.org/s/proposal-status#likely-accept)**.
â€” rsc for the proposal review group


--- Comment #18 by rsc ---

No change in consensus, so **[accepted](https://golang.org/s/proposal-status#accepted)**. ðŸŽ‰
