archive/zip: add file.openraw, writer.createraw, writer.copi
compress file, know uncompress size crc32 checksum, nice abl add archiv is.
three current use-cas this:
- repackag zip file, remov ad files, without incur associ compress overhead file alreadi exist (somewhat achiev
- compress first includ later base whether compress size smaller original, without perform compress twice.
- support concurr compression: compress mani file concurr copi alreadi compress file archiv (similar apach common compress' parallelscatterzipcreator)
see three differ way could achiev this:
1. creat `zip.createheaderraw(fh *fileheader) (io.writer, error)` function, use fileheader' `crc32` `uncompressedsize64` field set user.
2. use exist `createheader(fh *fileheader) (io.writer, error)` function, new filehead field indic go write alreadi compress data (and use `crc32` `uncompressedsize64` field set user)
3. use exist `createheader(fh *fileheader) (io.writer, error)` function, `compressedsize64` alreadi set, assum data written alreadi compressed.
go assum option 3 would no-go, exist code might suddenli break user alreadi set compresseds whatev reason, hope option viable.
/cc @dsnet
chang mention issue: `archive/zip: support ad raw files`
ad chang use option 1 (`createheaderraw`) feel weird use field `fileheader` sole archiv structur also use read archive.
go new api, turn proposal.
@dsnet pleas add thought may functionality. thanks.
project work would appreci function perform reasons. need replac singl file within zip. deflat tax high wast sinc decode/encod without need use intermedi data.
like @rsc' copi implement might quit flexibl proposals, think fit well within exist api support effici creat new zip exist zip allow user replace/delete/upd specif files.
```go
// Copy copies the file f (obtained from a Reader) into w.
// It copies the compressed form directly.
func (w *Writer) Copy(f *File) error {
	dataOffset, err := f.DataOffset()
	if err != nil {
		return err
	}
	if err := w.closeLastWriter(); err != nil {
		return err
	}
	fh := f.FileHeader
	h := &header{
		FileHeader: &fh,
		offset:     uint64(w.cw.count),
	}
	fh.Flags |= 0x8 // we will write a data descriptor
	w.dir = append(w.dir, h)
	if err := writeHeader(w.cw, &fh); err != nil {
		return err
	}
	r := io.NewSectionReader(f.zipr, dataOffset, int64(f.CompressedSize64))
	if _, err := io.Copy(w.cw, r); err != nil {
		return err
	}
	return writeDesc(w.cw, &fh)
}
```
latest compress/fl benchmark master level 5 archive/zip use default (intel xeon w-2135 cpu @ 3.70ghz √ó 6):
```
goos: linux
goarch: amd64
pkg: compress/flate
BenchmarkDecode/Digits/Level5/1e4-12         	    6530	    164347 ns/op	  60.85 MB/s	   40598 B/op	       7 allocs/op
BenchmarkDecode/Digits/Level5/1e5-12         	     960	   1131532 ns/op	  88.38 MB/s	   40842 B/op	      13 allocs/op
BenchmarkDecode/Digits/Level5/1e6-12         	     117	   9673619 ns/op	 103.37 MB/s	   44800 B/op	      79 allocs/op
BenchmarkDecode/Newton/Level5/1e4-12         	    8076	    164681 ns/op	  60.72 MB/s	   41114 B/op	      17 allocs/op
BenchmarkDecode/Newton/Level5/1e5-12         	    1653	    765625 ns/op	 130.61 MB/s	   44283 B/op	      31 allocs/op
BenchmarkDecode/Newton/Level5/1e6-12         	     180	   6408771 ns/op	 156.04 MB/s	   61144 B/op	     156 allocs/op
BenchmarkEncode/Digits/Level5/1e4-12         	    5710	    215617 ns/op	  46.38 MB/s
BenchmarkEncode/Digits/Level5/1e5-12         	     370	   3232511 ns/op	  30.94 MB/s
BenchmarkEncode/Digits/Level5/1e6-12         	      32	  34852520 ns/op	  28.69 MB/s
BenchmarkEncode/Newton/Level5/1e4-12         	    4774	    238334 ns/op	  41.96 MB/s
BenchmarkEncode/Newton/Level5/1e5-12         	     357	   2974790 ns/op	  33.62 MB/s
BenchmarkEncode/Newton/Level5/1e6-12         	      39	  30595764 ns/op	  32.68 MB/s
PASS
```
@escholtz agre `(*writer) copy(f *file)` would nice, said, quit flexible.
comparison, copi file patch submit would look someth like this:
```
func Copy(zw *zip.Writer, zf io.ReaderAt, f *zip.File) error {
	offset, err := f.DataOffset()
	if err != nil {
		return err
	}
	w, err := zw.CreateHeaderRaw(&f.FileHeader)
	if err != nil {
		return err
	}
	_, err = io.Copy(w, io.NewSectionReader(zf, offset, int64(f.CompressedSize64)))
	return err
}
```
`copy()` would great, reason one solut could added, prefer someth along line `createheaderraw`.
use case origin mentioned, written take advantag `createheaderraw` also (but vendor `archive/zip` includ modif work).
implement
vagu rememb discuss @rogpepp year ago, can't find discussion. clearer memory, roger?
memori come back. think rememb @rogpepp talk abil modifi exist zip file append new file it.
@rsc might discussion, yeah, relat appending.
ad whole new creat method set extra bit seem unfortun - second bit want control later? add four new methods? on.
probabl better add new bool createheader. perhap `writeraw bool`?
> probabl better add new bool createheader. perhap `writeraw bool`?
@rsc origin prefer too. reason implement `fileheader` also use read archiv too. felt odd `writeraw bool` part structur context reads. issue?
@saracen seem like less issu exponenti blowup creat methods. nonutf8 field probabl analogous, although get set reader.
suppos interest analog whether there' need get raw byte reader well. least could add openraw method zip.file. much harder createhead returns, io.writer.
suppos anoth way store compress file would regist no-op compressor.
anoth way would method zip.writer: writeraw(bool) set whether compressor avoided. z.writeraw(true) call createheader.
sound like winner anyone?
> suppos interest analog whether there' need get raw byte reader well.
@rsc moment, believ there' two way access raw bytes:
- open `readerat`, use `file.offset` `file.compressedsize64` access read specif section archive.
- regist decompressor whatev custom logic raw bytes.
> suppos anoth way store compress file would regist no-op compressor.
sound quit good, especi sinc similar handl raw read regist decompressor.
use `zip.noopcompressor` would need mean `compressedsize64` `crc32` field header left unmodifi header closed:
```golang
zw := zip.NewWriter(archive)
zw.RegisterCompressor(zip.Deflate, zip.NoOpCompressor)
hdr := &zip.FileHeader{
  Name: "file.txt",
  // the following fields would be left untouched because
  // the writer detects that zip.NoOpCompressor is being used
  CRC32: 0xffffffff,
  CompressedSize64: 1024,
}
w, _ := zw.CreateHeader(hdr) (io.Writer, error)
// bytes are copied to the zip archive unmodified
io.Copy(w, buf)
```
problem no-op compressor _uncompressed_ size would wrong. would left alone. probabl littl subtle.
given alreadi read compress data directly, @saracen point out, mayb fine focu writing.
pre-fil compressedsize64 (> 0) filehead mean write expect pre-compressed? case crc32 fill too, although zero valid crc32 can't double-check that. believ 0 valid compressedsize64, event interest one.
essence, compressedsize64 = 0 mean "i know, compress me".
**edit**: see @saracen' suggest 3 origin comment top.
@saracen, @escholtz, @klauspost, thought recent suggest (previou comment)?
accord rfc1951, compress stream requir least one block (with bfinal bit set). therefore, imposs compress deflat stream zero-byt length.
however, zip file format allow number differ compress method use (deflat happen common far). think think 1) whether want support compress methods, 2) whether ever want support compress format may theoret zero-length output empti input.
hesit comment want hijack @saracen' origin proposal.
use case, `func (w *writer) copy(f *file) error` implement would sufficient. think fit cleanli exist packag export still maintain simplicity.
agre `createheader` `createheaderraw` feel like clean standard librari package.
preced standard librari use compressedsize64 approach?
use case, `func (w *writer) copy(f *file) error` help, see use relat problem.
@rsc origin proposal, written:
> 3. use exist createheader(fh *fileheader) (io.writer, error) function, compressedsize64 alreadi set, assum data written alreadi compressed.
>
> go assum option 3 would no-go, exist code might suddenli break user alreadi set compresseds whatev reason, hope option viable.
break exist code reluct approach. see issue, sound like easi way support this.
@saracen took anoth look three exampl origin provid think could achiev copi method?
> * repackag zip file, remov ad files, without incur associ compress overhead file alreadi exist (somewhat achiev #15626)
use exist zip file(s), copi file want remove. copi exist file want keep. use exist method add new files.
> * compress first includ later base whether compress size smaller original, without perform compress twice.
write new zip file, read compress size, copi smaller.
> * support concurr compression: compress mani file concurr copi alreadi compress file archiv (similar apach common compress' parallelscatterzipcreator)
write multipl zip file concurr copi file singl zip file.
---
perhap approach eleg slightli garbage/perform overhead avoid tax repeatedli compress file would expect bottleneck cases.
> break exist code reluct approach. see issue, sound like easi way support this.
go code insid google, found one instanc someon implicitli set compressedsize. usag pattern look like following:
```go
rc, ... := rf.Open()
fileHeader := rf.FileHeader
wc, ... := w.CreateHeader(&fileHeader)
... io.Copy(wc, rc)
```
essenti code copi one zip file another.
go semant posit compresseds mean interpret input alreadi compressed, pattern break sinc `io.copy` read uncompress data `rc` write `wc` latter expect compress data.
could "fix" ad `readfrom` `writeto` method special handl copi compress data one `zip.file` another. however, approach seem bit magic see edg case fails.
@dsnet, think fix this, could least detect problem: alg deflat expect compress data, least check first byte proper deflat header. would make io.copi return error. littl concerning.
> proper deflat header.
unfortun deflat realli distinguish magic number unlik gzip, typic 10-byte sequenc readili identifiable. seem best could decompress number byte assum input valid pass short test.
sound like look go corpu code use pattern. tri next week. mayb overload compresseds subtle.
tri next time.
feel like loos interest propos draw conclusion.
think overload compresseds good approach.
still like copi approach @rsc chose use zipmerg package. think 3 use case origin propos solv copi method.
@escholtz, yet done scan, seem like necessari - plausibl exampl break.
one thing would still good support would header bit hand along compress form, already-exist zip file. (mayb want control compression, deflat altern compress form alreadi differ archiv file, someth like that.)
reread thread bit distance, think fundament oper realli access raw data read writing. suggest add directly, along copi helper:
// like createhead data written io.writ precompress
func (*writer) createraw(fil *fileheader) (io.writer, error)
// like open data read back compress form
func (*file) openraw() (io.reader, error)
// helper - f.openraw, w.createraw, io.copi
func (w *writer) copy(f *file) error
sound reasonable. look package, assum type access intent export simplic reliability. ok make packag littl less simple, would enabl advanc use case tri achieve.
hi everybody! :smile:
think coupl months. long think creat solution.
dream put idea live found issu :laughing:
far 2 problem mind
1. copi file without decompression-compression.
2. precompress multipli files. compress parallelli
differ iter mind. first someth like @saracen mention similar look readcompr method. dirti monstrous. far long think creat absolut copi `copy` method :laughing: :laughing: :laughing: even optim `writedesc` func. geniu moment :smile: discov task could done `copy` method.
happi still add penni probabl resolv discuss blow methods.
need `createraw(fil *fileheader)` method. probabl `openraw() (io.reader, error)` also.
easi resolv `copy`
idea
```
func main() {
       // final writer
	zw := zip.NewWriter(bytes.NewBuffer([]byte{}))
       // get precompressed zip.File
	prFile := Precompress(data)
       // copy precompressed zip.File
	zw.Copy(prFile)
}
func Precompress(b []byte) zip.File {
	// create tmp zip writer
	buf := bytes.NewBuffer([]byte{})
	zw := zip.NewWriter(buf)
       // write/compress data in
	zwf, _ := zw.Create("test")
	zwf.Write(b)
	// extract file from tmp zip
	zr,_  := zip.NewReader(readerAt(buf.Bytes()), int64(buf.Len()))
	return zr.File[0]
}
```
way compression, descriptor valid logic still encapsulated(!). overhead (i think) . compress data buffer io.copi destin reader. case compress directly.
case user want copi coupl file big zip keep memory. done `copy`. user copi need file tmp zip need copi destin zip.
think `openraw()` method before. much use case far. user need keep 1 file compress state use tmp zips. use case user want extract raw file send directli http client :thinking: . first iter achiev `compressor` interface. copi data buffer ignor error crc2 check. work pretti well long time. post code find it.
*conclusion*
1. `copy` method critic
2. method implement wrapper without overhead
> suggest add directly, along copi helper:
@rsc
- sure need `openraw`, mention there' alreadi way access raw data. although, `openraw` probabl clearer.
- personally, prefer `createheaderraw` `createraw`, think clearer variant `createheader`.
- think `copy` also ad üëç
@klauspost' `compress` librari ad `createheaderraw` `copy`. obviously, extern library, would *nice* api continu match.
@im7mort use `copy` work @escholtz suggest too. good solut mani problems, reli either precompress data zip file first copi one. copi precompress data differ archiv format would requir temporari copi new zip file, read back again.
