=== Fetching Proposal: MDU6SXNzdWU4OTYyMDM4Nzg= ===
Issue URL: https://github.com/golang/go/issues/46279

==== [Issue Title] ====
runtime: automatically bump RLIMIT_NOFILE on Unix

==== [Issue Body] ====
I just read http://0pointer.net/blog/file-descriptor-limits.html which in a nutshell says:

* don't use `select`
* systemd sets the RLIMIT_NOFILE soft limit to 1024 for compatibility reasons, to not break `select` users
* systemd sets the RLIMIT_NOFILE hard limit 512K, for programs that want more (without escalation), but by raising their soft limit past 1024, they're implicitly acknowledging that `select` won't work.

I realize that since Go doesn't use select, the Go runtime could automatically do this fd soft limit bumping on Linux.

We do have a Select wrapper at https://pkg.go.dev/golang.org/x/sys/unix#Select, though, so perhaps we could do the same thing we did for #42347 in 18510ae88ffcb9c4a914805fde3e613539f9b6dc (https://go-review.googlesource.com/c/go/+/299671) and do the bumping conditionally based on whether the `unix.Select` func is in the binary. Or `cgo` too, I suppose.

I suspect many users are unaware of this 512K hard limit that's free to bump up to. I certainly was unaware. (I normally have to go in and manual tweak my systemd limits instead, usually in response to problems once I hit the limit...)  I think fixing it automatically would help more users than it'd hurt. (I actually can't think how it'd hurt anybody?)

I don't think we need it as a backpressure mechanism. As the blog post mentions, memory limits are already that mechanism.

/cc @ianlancetaylor @aclements @rsc @randall77 

==== [Comments] ====

--- Comment #1 by ianlancetaylor ---
The limitation on `select` is not a kernel limitation.  It's a limitation on the implementation of `fd_set` in glibc.  And we've inherited that limitation in `x/sys/unix.FdSet`, but perhaps we could fix that.  If we did, then we could raise the soft limit to the hard limit unconditionally.

I note that on my Debian system the soft and hard limits are both `131072`.  On my CentOS 6 system the soft limit is `1024` and the hard limit is `4096`.  On my recent Fedora system the soft limit is `1024` and the hard limit is `524288`.

--- Comment #2 by bradfitz ---
Yeah, I saw `FdSet` was `struct { Bits [16]int64 }`. Make it opaque with a `[16]int64` used by default and a spill-over lazily-allocated bitmap when `(*FDSet).Set(fd int)` is called with a "big" fd? Doable, but I wonder if it's worth the effort. Does anybody actually use `unix.Select`?

We'd still need a conditional mechanism regardless for `cgo` I assume, as we wouldn't know whether C code was using select as easily?

FWIW, on my various Debian (buster) & Ubuntu (focal LTS, hirsute) machines here, I see 1024 & 1048576.

--- Comment #3 by bradfitz ---
> Does anybody actually use unix.Select?

GitHub code search says https://github.com/search?l=&p=2&q=unix.Select+language%3AGo&type=Code .... it's mostly wireguard-go's `rwcancel` package. 

(cc @zx2c4 as FYI)

--- Comment #4 by zx2c4 ---
~I'm happy to get rid of that and replace it with poll. (Want to send a patch?)~ Done: https://git.zx2c4.com/wireguard-go/commit/?id=a9b377e9e10eb5194c0bdff32136c11b17253bfd

This proposal sounds like a good idea, with the caveat that we probably shouldn't do it in initialization for -buildmode=shared.

--- Comment #5 by rsc ---
What happens today, even in programs that do nothing but file I/O (no select etc), is that if you open too many files you get errors. Auto-bumping would let those programs run longer.

If Go did it at startup, it would be inherited by non-Go programs that we fork+exec. That is a potential incompatibility, but probably not a large one. Technically, I suppose we could undo it in the subprocess between fork and exec.



--- Comment #6 by rsc ---

This proposal has been added to the [active column](https://golang.org/s/proposal-status#active) of the proposals project
and will now be reviewed at the weekly proposal review meetings.
â€” rsc for the proposal review group


--- Comment #7 by nightlyone ---
To summarize the limitating use cases where we should not be raising the soft limit.
* select implementation from glibc (or other libc like musl too?) is used
* cgo is used because dynamic linking can load anything with dlopen and also can cause exec calls in places we don't know.
* select implementation from our own syscalls or unix package is used, unless that one is changed as suggested above.
* NSS (user/group lookup and DNS lookup) is used from glibc.
* and we need to reset, if we call the exec family of syscalls

--- Comment #8 by rsc ---
One problem with restoring the limit in exec is we won't know if the limit was intentionally changed by the program in the interim. What about programs that explicitly raise the limit and then exec today? We would be dropping it back down.

It seems like if we are going to raise the limit, we should just do that, not try to put it back. 

I just ran into this problem with gofmt on my Mac, where the limit defaults to 256 (and gofmt was editing many files in parallel). I'd love for Go to raise the limit there too.

How much does it really matter if we raise the limit for a subprocess?

People can always set the hard limit if they want Go not to try to bump the soft limit up.

--- Comment #9 by rsc ---
It's pretty awful that the limit is breaking completely reasonable Go programs like gofmt -w. 
It seems very wrong for gofmt to have to put a bump in.
It seems like we should bump the limit at startup - Go doesn't use select.

It's very hard to see any programs benefiting from this limit in practice anymore.
I understand that systemd can't make such a global decision, but I think Go can.


--- Comment #10 by zx2c4 ---
I think that seems quite reasonable.

We can even document this in `unix.Select`/`syscall.Select` and mark them as deprecated so that editors bring attention to them and maybe add something to `go vet` too. It seems always possible to move to poll or similar.

--- Comment #11 by rsc ---
Not sure anyone is using syscall.Select for fd's anyway. 
Every time I've used it in the past decade it has been to get a sub-second-resolution sleeping API (selecting on no fds).


--- Comment #12 by rsc ---

Based on the discussion above, this proposal seems like a **[likely accept](https://golang.org/s/proposal-status#likely-accept)**.
â€” rsc for the proposal review group


--- Comment #13 by AlekSi ---
Should the title be updated to mention Unix or something instead of Linux?
Personally, I constantly run into that limitation on macOS; would like to see that resolved.

--- Comment #14 by ianlancetaylor ---
The considerations may be different on different Unix systems.  On Linux the details are somewhat specific to systemd.

It may well be appropriate to do this on macOS also, but I don't know what the tradeoffs are there.  Why does macOS have a default low limit?

--- Comment #15 by AlekSi ---
From what I was able to find, that default goes back to the very first OS X release and probably even back to BSD. The constant is [there](https://github.com/apple-oss-distributions/xnu/blob/bb611c8fecc755a0d8e56e2fa51513527c5b7a0e/bsd/sys/param.h#L101).

Of course, not doing that on macOS is not a deal-breaker but an annoyance.

--- Comment #16 by kolyshkin ---
The only issue I am aware of that can arise if RLIMIT_NOFILE is set to a very high value is, some binaries (that may be executed from a Go program and thus inherit the limit) want to do something like this (pseudocode):
```go
for fd := 3; fd < getrlimit(RLIMIT_NOFILE); fd++ {
      close(fd) // or set CLOEXEC flag
}
```

For a specific example, `rpm` package manager used to do that (fixed by https://github.com/rpm-software-management/rpm/commit/5e6f05cd8dad6c1ee6bd1e6e43f176976c9c3416), and also some older version of Python (but I'm not sure).

Most probably this should not be an issue, since Docker also does a similar thing (https://github.com/moby/moby/issues/38814) and since everyone seems to be using containers now, let's hope that issues like this are fixed (yet better, maybe some programs have even started using `close_range()`).

Also, this is surely not a showstopper to accept the proposal -- just something to keep in mind.

--- Comment #17 by rsc ---

No change in consensus, so **[accepted](https://golang.org/s/proposal-status#accepted)**. ðŸŽ‰
This issue now tracks the work of implementing the proposal.
â€” rsc for the proposal review group


--- Comment #18 by gopherbot ---
Change https://go.dev/cl/392415 mentions this issue: `os: raise open file rlimit at startup`

--- Comment #19 by gopherbot ---
Change https://go.dev/cl/393016 mentions this issue: `Revert "os: raise open file rlimit at startup"`

--- Comment #20 by bcmills ---
The test for this change is failing on at least three builders â€” looks like we may need to plumb in `OPEN_MAX` for the case where `getrlimit` reports `RLIM_INFINITY` instead of the true max.

--- Comment #21 by rsc ---
I'm confused about needing `OPEN_MAX`:

On my Mac with macOS 12.2:

```
% ulimit -n
ulimit -n 256
% ulimit -nH
ulimit -n unlimited
% ulimit -n unlimited
% ulimit -n
ulimit -n unlimited
% 
```

I've always used 'ulimit -n unlimited' without trouble on Macs. I wonder if the struct definitions are wrong.


--- Comment #22 by bcmills ---
It looks like the macOS `setrlimit` behavior may have changed as of 11.0.
(The 10.14 and 10.15 builders broke, but the 11.0 and 12.0 builders did not.)

--- Comment #23 by bcmills ---
So I suppose one option might be to try the `setrlimit` call with the limit as given by `getrlimit`, and if that fails fall back to increasing to some reasonable-but-arbitrary constant (ideally equal to `OPEN_MAX`)..?

--- Comment #24 by ianlancetaylor ---
Some more info at #40564.

--- Comment #25 by rsc ---
I put in a call to sysctl kern.maxfilesperproc. Hopefully that exists on the older macOS. And I skipped the OpenBSD failure entirely. (It is not a first-class port.)


--- Comment #26 by gopherbot ---
Change https://go.dev/cl/393354 mentions this issue: `os: raise open file rlimit at startup`

--- Comment #27 by gopherbot ---
Change https://go.dev/cl/394094 mentions this issue: `os: skip TestOpenFileLimit on openbsd/mips64`

--- Comment #28 by polarathene ---
> How much does it really matter if we raise the limit for a subprocess?
> People can always set the hard limit if they want Go not to try to bump the soft limit up.

> I understand that systemd can't make such a global decision, but I think Go can.

FWIW, `containerd` previously could use systemd to configure limits with `LimitNOFILE=1024:524288` in a service file. All containers and the processes they run would inherit those limits, and could optionally raise their own soft limits.

Since Go 1.19, providing an explicit soft limit this way does not work anymore. It'll get raised implicitly to the hard limit assigned, I'm not sure if `containerd` was aware of this as their default config shipped is `LimitNOFILE=infinity`.

High `RLIMIT_NOFILE` (especially the soft limit) has been a source of confusion and difficult to troubleshoot problems from users when software (particularly daemons) was not designed to operate on a range spanning over a billion file descriptors (_each with a `close()` syscall and the majority not open_) stalling with heavy CPU load, or allocating ridiculous amounts of memory (thousands more).

---

Presently, if one relies on the default limits systemd assigns (`1024:524288`), even on Debian based systems where the system-wide hard limit per-process (`fs.nr_open`) is `1048576` (`2^20`) instead of `2^30`, the implicit behaviour could not be opt-out by the user, ~~unless they raise the hard limit to `infinity`.~~ (_**EDIT:** Mishap on my end, not actually supported_)

~~Was it intentional to require assigning a hard limit as high as `2^30` to a process, just so a lower soft limit could be applied?~~

I understand this is technically niche (_beyond the popularity of the software itself_), but due to each process belonging to a container, and each container belonging to the parent `containerd`, the hard limit for `containerd` needs to be sufficiently high, but a soft limit at that same limit is worse to troubleshoot abnormal behaviour vs an error message of too many files being open.

---

I've reported the regression to `containerd`, and assume it's something they should attempt to resolve on their end? (_assuming they can opt-out internally, or know the original soft-limit_)

--- Comment #29 by ianlancetaylor ---
@polarathene I don't see the connection between what you describe and the Go runtime.  Is `containerd` a Go program?  If so, I agree that they should be aware of this change and should configure their limits accordingly.

--- Comment #30 by polarathene ---
> I don't see the connection between what you describe and the Go runtime. 

`containerd` creates containers, which run various processes, they all are run from the same `containerd` process parent, thus inherit the limit.

Setting a soft limit on the OS for `containerd` to respect worked well until Go 1.19 released (and a new release of `containerd` arrived). Now the intended soft limit is ignored.

As a consumer of a Go program - One must now choose a practical hard limit without control of the soft limit.

This Go 1.19 change is the source of that regression slipping through (_I don't think many Go programs had tests in place to ensure limits set externally were respected, since that was reliable / consistent when set explicitly via `ulimit` or similar_). This was not something `containerd` had to decide / manage internally.

> Is `containerd` a Go program?

Yes, it is heavily used for for containers with Docker and Kubernetes:
- https://containerd.io/
- https://github.com/containerd/containerd

---

> If so, I agree that they should be aware of this change and should configure their limits accordingly.

I am not a Go developer, and it's not clear to me if the "feature" supports opt-out?

I have raised a bug report to `containerd` as mentioned earlier, but I'm not sure if the changes introduced here for Go 1.19 still allow for running with the original inherited limits like before Go 1.19?

Can `containerd` still know the original soft limit and restore that value? Or is it lost by the time the limit is raised implicitly?

---

`containerd` relied on external limits being set for this (_while shipping a default in the past of `1048576`, presently `infinity`_) as the relevant limits depend on environment (eg: _local dev vs production at scale_).
- The limits can make some builds in containers take **10 hours instead of 15 minutes**.
- In my own experience a popular Python project that would **start in 1 second would instead take 70 minutes**. These can generally be avoided by a soft limit, and this will still work with Go 1.19 if using `infinity` as the hard limit.
- Some software has been known to behave similar to Go 1.19 and implicitly raise soft to high limit, but also not intended to run with a hard limit as large as a billion, which at that size **allocates excessive amounts of memory causing failure from OOM**_).

There are workarounds available at the container level, but these were not needed previously (_configuring `RLIMIT_NOFILE` in a systemd unit that is applied before running `containerd`_).

I just wanted to chime in and raise awareness of a problem case from this change. As a user, it was a surprise that my explicit soft limit was not respected (_because I did not want to have a hard limit of `infinity`_).


