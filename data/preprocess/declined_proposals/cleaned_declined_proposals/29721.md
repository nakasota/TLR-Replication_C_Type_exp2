==== [Issue Title] ====
proposal: x/sync/semaphore: make semaphore resizable

==== [Issue Body] ====
Hello,

Semaphores are often used to bound concurrency, for example I was implementing a goroutines pool pattern with weighted jobs, so a weighted semaphore is better and more performant than channel-based semaphore. a common functionality in goroutines pool is to be resizable, however the current `sync/x/semaphore` doesn't allow resizing the semaphore.

There is another implementation of a non-channel-based semaphores that supports resizing, but I found many bugs/deadlocks using them and they're all less performant than `x/sync/semaphore`.

The current implementation of `x/sync/semaphore` can be easily extended to be resizable, without affecting performance by any means.

==== [Comments] ====

--- Comment #1 by bcmills ---
CC @jba @Sajmani

--- Comment #2 by bcmills ---
This proposal needs more detail.

* What are some concrete use-cases for resizable semaphores? (Links to existing code that could be replaced or improved by this change would be ideal.)

* What is the specific API being proposed?
   * Does it add and remove capacity, or set the capacity to an absolute quantity?
   * If it sets the absolute quantity, what happens if that capacity is lower than the number of outstanding tokens?

--- Comment #3 by bcmills ---
Note that if you have *some* upper bound, you can already ‚Äúresize‚Äù a `semaphore.Weighted` by acquiring and releasing surplus tokens:

```go
const (
	maxCap = [‚Ä¶]
	initialCap = [‚Ä¶]  // ‚â§ maxCap
)
sem := semaphore.NewWeighted(maxCap)
sem.Acquire(ctx, maxCap - initialCap)
// Effective capacity of sem is now initialCap,
// but it can be ‚Äúresized‚Äù up to maxCap by releasing tokens.
```

--- Comment #4 by sherifabdlnaby ---
@bcmills 

###  Example:
[cockroachdb](https://github.com/cockroachdb/cockroach) uses a semaphore for rate limiting, I found a bug (https://github.com/cockroachdb/cockroach/issues/33554) in the semaphore package they were using that has potential to deadlock.
They decided to keep using this semaphore implementation because the bug was not currently reachable in their code and **there aren't many alternative resizable semaphores**. https://github.com/cockroachdb/cockroach/issues/33554#issuecomment-452787625

fixing the bug in that mentioned semaphore implementation halved its performance (300% slower than x/sync/semaphore) according to benchmarks.

-------

###  What is the specific API being proposed?
> Does it add and remove capacity, or set the capacity to an absolute quantity?

It sets the capacity to an absolute quantity.

> If it sets the absolute quantity, what happens if that capacity is lower than the number of outstanding tokens?

If semaphore is resized to a number lower than the current acquired tokens it will not acquire any new tokens until a release that brings down current capacity to be lower or equal to the new semaphore capacity.

------

### More details

#### What happens to the Aquire of N that was marked impossible and not added to waiters list ? and what happens if an Aquire of N that was already in the waiting list when a resize lower the capacity to be < N ? 

In the current Implementation an Aquire of `N` where `N` is > `capacity` will not be added to the waiters' linked list because It is impossible to get acquired.  and will block forever unless cancelled by its ctx.

In the PR, I've added a new linked-list for the impossible waiters, when Acquire(`N`) is impossible it will be added to the impossible waiters list, Impossible waiters can become possible if a resize of the semaphore was big enough.

So now when Resize(`N`) is called this is what happens:
1. Set a new size for the semaphore.
2. Will loop through the waiters list removing the now-impossible waiters to the impossible waiters.
3. Will loop through the Impossible Waiters list adding the now-possible ones to the waiters list.
4. Will signal possible waiters from the front of the waiters list to unblock ( same as Release() mechanism).

A resize is **O(W+I)**, W = length of waiters list, I = length of impossible waiters list.

--- Comment #5 by sherifabdlnaby ---
> Note that if you have _some_ upper bound, you can already ‚Äúresize‚Äù a `semaphore.Weighted` by acquiring and releasing surplus tokens:
> 
> ```go
> const (
> 	maxCap = [‚Ä¶]
> 	initialCap = [‚Ä¶]  // ‚â§ maxCap
> )
> sem := semaphore.NewWeighted(maxCap)
> sem.Acquire(ctx, maxCap - initialCap)
> // Effective capacity of sem is now initialCap,
> // but it can be ‚Äúresized‚Äù up to maxCap by releasing tokens.
> ```

Yes, this will work effectively if you have an upper-bound.
I believe a simple .Resize(`N`) will be simpler to use.

--- Comment #6 by bcmills ---
`math.MaxInt64` is always a valid upper bound.

So it seems the only behavioral difference today is the FIFO behavior of ‚Äúimpossible‚Äù tasks. Those are not generally something you want to have in a well-behaved system anyway, since they consume resources while waiting for cancellation; so, how often does that difference matter?

--- Comment #7 by sherifabdlnaby ---
@bcmills 
> math.MaxInt64 is always a valid upper bound.

Yes it's, but this will allow impossible tasks to be added to waiters list and will block other waiters when that impossible task is at the front of the list thus causing a deadlock which is unexpected semaphore behavior.

I understand your point that it is not generally something you want to have in a well-behaved system anyway.

But my opinion is a `Resize()` would be simpler to use than an ad-hoc way to resize the semaphore that may have unexpected deadlocks because of the semaphore implementation.

--- Comment #8 by rsc ---
/cc @jba 

--- Comment #9 by rsc ---

This proposal has been added to the [active column](https://golang.org/s/proposal-status#active) of the proposals project
and will now be reviewed at the weekly proposal review meetings.
‚Äî rsc for the proposal review group


--- Comment #10 by sherifabdlnaby ---
@rsc This is great news, I've been using my fork for a long time, and having it part of the official/x/sync/semaphore` will be very welcomed.
I updated the PR golang/sync#3 and sync it with upstream changes.

--- Comment #11 by rsc ---
@sherifabdlnaby Can you say something about why you are maintaining a fork instead of using a wrapper that does the trick @bcmills mentioned with allocating a very large-sized semaphore but then using Acquire and Release calls to take capacity away / bring it back?



--- Comment #12 by sherifabdlnaby ---
@rsc 
Using the approach suggested by @bcmills was not ideal in my usecase, in [func (s *Weighted) notifyWaiters() #L117](https://github.com/golang/sync/blob/036812b2e83c0ddf193dd5a34e034151da389d09/semaphore/semaphore.go#L117) you see that when a resource is released; *only the front of the waiters is tried for the acquiring* and if no tokens are available it explicitly avoids looking up another possible smaller acquires to avoid starvation.

Hence, when trying to acquire the semaphore with **weight > *the effective size of the semaphore*** it blocks the semaphore until a resize that makes the weight <= effective size; it will not let smaller semaphores get acquired despite blocking forever until the semaphore is resized again.

In my implementation the acquires that their weight >= the size of the semaphore are moved to a separate *impossibleWaiters* queue and is only added to the semaphore queue when it's possible for them to be acquired eventually (checked at every invocation of `resize()` function).

In my use-case, this was very important to the performance of the semaphore. I use it for dynamically bounding concurrency and needed a more performant method than channel-based semaphores.

--- Comment #13 by jba ---
I don't see anything wrong with this proposal technically. It would be different if Acquire rejected impossible requests, but instead it lets them wait indefinitely. The only difference here (assuming Resize is never called) is some extra space, negligible compared to the goroutine's memory.

The effect of Resize cannot be obtained with the existing semaphore, for the reason explained above: when you resize down, you can deadlock because the waiter at the front of the list can never proceed.

The use case of weighted tasks with dynamic concurrency seems like a reasonable one.

--- Comment #14 by ajwerner ---
> cockroachdb uses a semaphore for rate limiting, I found a bug (cockroachdb/cockroach#33554) in the semaphore package they were using that has potential to deadlock.
They decided to keep using this semaphore implementation because the bug was not currently reachable in their code and there aren't many alternative resizable semaphores. cockroachdb/cockroach#33554 (comment)
> 
> fixing the bug in that mentioned semaphore implementation halved its performance (300% slower than x/sync/semaphore) according to benchmarks.

Thanks for the reminder on this. In other use cases, CockroachDB has generally decided to stop using the semaphore library altogether. That library is not very good from a fairness or allocation perspective. The [quotapool](https://github.com/cockroachdb/cockroach/tree/master/pkg/util/quotapool) library provides fairness, resizing, and dramatically more flexibility. This library has proven to be quite good. I'll pick it up in our internal `limit` package and I'll try to work on getting it spun out into an Apache license somewhere. 

--- Comment #15 by rsc ---
@sherifabdlnaby thanks for the reply, specifically:

> In my implementation the acquires that their weight >= the size of the semaphore are moved to a separate impossibleWaiters queue and is only added to the semaphore queue when it's possible for them to be acquired eventually (checked at every invocation of resize() function).

It sounds like your semaphore is not first come, first served, while the Go implementation is. So in addition to making it resizable you are also asking for the policy to be changed about how requests are satisfied. I am less sure about making that change. Thoughts on that part, @bcmills and @jba?
 

--- Comment #16 by sherifabdlnaby ---
@rsc 

> It sounds like your semaphore is not first come, first served, while the Go implementation is. So in addition to making it resizable you are also asking for the policy to be changed about how requests are satisfied. 

The policy stays as first come, first served **as long the requests are satisfiable**, when a request is **impossible to be acquired** given the current size of the semaphore, it will be moved to the impossibleWaiters queue; now when It is possible to be acquired (after a resize) **it will be put back at the end of the main queue**. 

So essentially the policy is the same as long as you have not introduced `resize()` (and having a request that is > the size of the semaphore). making the change backward compatible and non-breaking to existing behavior.


--- Comment #17 by jba ---
@sherifabdlnaby, did you check out the quotapool package mentioned [above](https://github.com/golang/go/issues/29721#issuecomment-800692302)? That sounds like an improvement on what you're proposing here.

--- Comment #18 by sherifabdlnaby ---
@jba I didn't know about the quotapool package at the time I needed the resizable semaphore. It looks pretty sophisticated and I would definitely try it.
I don't know how much overhead is added to achieve such sophistication, I'll have to benchmark it. The reason I needed a resizable semaphore is I needed a more performant worker pool than the one that uses channels as a semaphore.

--- Comment #19 by ajwerner ---
> I don't know how much overhead is added to achieve such sophistication, I'll have to benchmark it. The reason I needed a resizable semaphore is I needed a more performant worker pool than the one that uses channels as a semaphore.

Let me know what you discover! I tuned the thing somewhat heavily. It has a fast path which avoids using channels if there is sufficient quota. Any allocations are pooled so generally there are no allocations to interact with it. The channels are also pooled as it is designed to not close them but rather recycle them. 

--- Comment #20 by rsc ---
Given that @sherifabdlnaby has a customized fork and also @ajwerner has written another package to serve the specific need, and given that to serve this need in x/sync/semaphore would require changing the queueing order for pending requests, it sounds like we probably should leave x/sync/semaphore's semantics alone and encourage the use of alternate packages when they are a better fit.



--- Comment #21 by rsc ---

Based on the discussion above, this proposal seems like a **[likely decline](https://golang.org/s/proposal-status#likely-decline)**.
‚Äî rsc for the proposal review group


--- Comment #22 by sherifabdlnaby ---
Thanks all for your time discussing this üôèüèª 

--- Comment #23 by rsc ---

No change in consensus, so **[declined](https://golang.org/s/proposal-status#declined)**.
‚Äî rsc for the proposal review group

