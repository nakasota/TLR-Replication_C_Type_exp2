#!/usr/bin/env python3
"""
æ”¹è‰¯ç‰ˆCLChangeFetcher: ã‚ˆã‚Šæ­£ç¢ºãªé–¢æ•°å¤‰æ›´æ¤œå‡º

ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ä»¥ä¸‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¾ã™ï¼š
1. CLã®ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’tree-sitterã§åˆ†æã—ã¦é–¢æ•°ã‚’å–å¾—
2. diffæƒ…å ±ã‹ã‚‰å¤‰æ›´ã•ã‚ŒãŸè¡Œã®å†…å®¹ã‚’å–å¾—  
3. å¤‰æ›´ã•ã‚ŒãŸè¡Œã®å†…å®¹ã¨é–¢æ•°ã®å†…å®¹ã‚’æ¯”è¼ƒ
4. å¤‰æ›´ã«ãƒ’ãƒƒãƒˆã—ãŸé–¢æ•°ã‚’CLã§å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã¨ã—ã¦ç‰¹å®š
"""

import json
import re
import requests
import time
import base64
import binascii
import urllib.parse
from typing import Dict, List, Optional, Set, Tuple, Any
import logging
import tree_sitter

logger = logging.getLogger(__name__)

class SimpleRepoLoader:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒªãƒã‚¸ãƒˆãƒªãƒ­ãƒ¼ãƒ€ãƒ¼å®Ÿè£…"""
    
    def __init__(self, repo_path: str = "."):
        self.repo_path = repo_path
        self.logger = logging.getLogger(__name__)
    
    def get_file_content(self, file_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—ã—ã¾ã™"""
        try:
            import os
            full_path = os.path.join(self.repo_path, file_path)
            if os.path.exists(full_path):
                with open(full_path, 'r', encoding='utf-8') as f:
                    return f.read()
            return None
        except Exception as e:
            self.logger.warning(f"Error reading file {file_path}: {str(e)}")
            return None
    
    def get_all_files(self) -> List[str]:
        """ãƒªãƒã‚¸ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™"""
        try:
            import os
            all_files = []
            for root, _, files in os.walk(self.repo_path):
                for file in files:
                    if file.endswith('.go'):
                        rel_path = os.path.relpath(os.path.join(root, file), self.repo_path)
                        all_files.append(rel_path)
            return all_files
        except Exception as e:
            self.logger.warning(f"Error listing files: {str(e)}")
            return []

class ImprovedCLChangeFetcher:
    def __init__(self, repo_loader=None):
        """
        Initialize the improved CL change fetcher.
        
        Args:
            repo_loader: Repository loader instance for accessing current repository content
        """
        self.repo_loader = repo_loader
        self.logger = logging.getLogger(__name__)
        
        # Initialize tree-sitter parser
        self.go_language = None
        self.parser = None
        self._initialize_tree_sitter()

    def _initialize_tree_sitter(self):
        """tree-sitterãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        try:
            import os
            # ãƒ‘ãƒ¼ã‚µãƒ¼ã®ãƒ‘ã‚¹ã‚’æ¤œç´¢
            possible_paths = [
                'tree-sitter-build/tree-sitter-go/src/parser.so',
                'tree-sitter-build/lib/tree-sitter-go.so',
                'tree-sitter-build/tree-sitter-go/libtree-sitter-go.so',
                'tree-sitter-build/tree-sitter-go/parser.so',
                os.path.join(os.path.dirname(__file__), '../tree-sitter-build/tree-sitter-go/src/parser.so'),
                os.path.join(os.path.dirname(__file__), '../tree-sitter-build/lib/tree-sitter-go.so')
            ]
            
            parser_path = None
            for path in possible_paths:
                if os.path.exists(path):
                    parser_path = path
                    break
            
            if not parser_path:
                raise RuntimeError("Could not find tree-sitter-go parser in any expected location. Please ensure the parser is built correctly.")
            
            from tree_sitter import Language
            self.go_language = Language(parser_path, 'go')
            self.parser = tree_sitter.Parser()
            self.parser.set_language(self.go_language)
            logger.info(f"âœ“ tree-sitter Go parser loaded from {parser_path}")
        
        except ImportError as e:
            logger.error(f"tree-sitter module not found: {str(e)}")
            logger.error("Please install tree-sitter: pip install tree-sitter")
            raise
        except RuntimeError as e:
            logger.error(f"tree-sitter-go parser not found: {str(e)}")
            logger.error("Please build the parser using the build script in tree-sitter-build/")
            raise
        except Exception as e:
            logger.error(f"tree-sitter initialization failed: {str(e)}")
            raise

    def extract_changed_functions_advanced(self, cl_number: str, file_path: str) -> Set[str]:
        """
        æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
        
        ãƒ•ãƒ­ãƒ¼:
        1. CLã‹ã‚‰å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’å–å¾—
        2. diffæƒ…å ±ã‹ã‚‰å®Ÿéš›ã®å¤‰æ›´å†…å®¹ã‚’å–å¾—
        3. å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’tree-sitterã§è§£æã—ã¦é–¢æ•°ã‚’æŠ½å‡º
        4. diffå¤‰æ›´å†…å®¹ã¨é–¢æ•°å†…å®¹ã‚’ãƒãƒƒãƒãƒ³ã‚°ã—ã¦å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã‚’ç‰¹å®š
        5. ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèª
        6. è©²å½“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§é–¢æ•°åã®ä¸€è‡´ç¢ºèª
        
        Args:
            cl_number: CLç•ªå·
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°åã®ã‚»ãƒƒãƒˆï¼ˆç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã«å­˜åœ¨ã™ã‚‹é–¢æ•°ã®ã¿ï¼‰
        """
        try:
            self.logger.info(f"Processing {file_path} with advanced approach...")
            
            # CLã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
            cl_info = self._get_cl_info(cl_number)
            if not cl_info:
                self.logger.warning(f"Failed to get CL info for {cl_number}")
                return set()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æƒ…å ±ã‚’å–å¾—
            file_changes = self._get_file_changes(cl_number)
            if not file_changes:
                self.logger.warning(f"Failed to get file changes for {cl_number}")
                return set()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆsrc/ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ï¼‰
            normalized_file_path = file_path
            if normalized_file_path.startswith('src/'):
                normalized_file_path = normalized_file_path[4:]
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’å–å¾—
            directory_path = '/'.join(normalized_file_path.split('/')[:-1]) if '/' in normalized_file_path else ''
            self.logger.info(f"  ğŸ“‚ æ­£è¦åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {normalized_file_path}")
            self.logger.info(f"  ğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹: {directory_path}")
            
            # 2. diffæƒ…å ±ã‹ã‚‰å¤‰æ›´å†…å®¹ã‚’å–å¾—
            diff_info = self._get_file_diff_content(cl_number, file_path)
            if not diff_info or not diff_info.get('changed_line_contents'):
                self.logger.warning(f"  âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {file_path} (diffæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“)")
                return set()
            
            self.logger.info(f"  ğŸ“Š å¤‰æ›´è¡Œæ•°: {len(diff_info.get('changed_line_contents', set()))}")
            self.logger.info(f"  ğŸ“Š å¤‰æ›´å†…å®¹ã‚µãƒ³ãƒ—ãƒ«: {list(diff_info.get('changed_line_contents', set()))[:3]}")
            
            # 3. CLã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—ã—ã¦tree-sitterã§è§£æ
            cl_content = self._get_cl_file_content(cl_number, file_path)
            if not cl_content:
                self.logger.warning(f"  âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {file_path} (CLã®å†…å®¹ã‚’å–å¾—ã§ãã¾ã›ã‚“)")
                return set()
            
            cl_functions = self._extract_functions_from_source(cl_content)
            if not cl_functions:
                self.logger.warning(f"  âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {file_path} (CLã‹ã‚‰é–¢æ•°ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“)")
                return set()
            
            self.logger.info(f"  ğŸ“Š CLå†…é–¢æ•°æ•°: {len(cl_functions)}")
            self.logger.info(f"  ğŸ“Š CLå†…é–¢æ•°ã‚µãƒ³ãƒ—ãƒ«: {list(cl_functions.keys())[:3]}")
            
            # 4. diffå¤‰æ›´å†…å®¹ã¨é–¢æ•°å†…å®¹ã‚’ãƒãƒƒãƒãƒ³ã‚°ã—ã¦å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã‚’ç‰¹å®š
            changed_functions_in_cl = self._find_changed_functions_by_content_matching(
                cl_content, cl_functions, diff_info
            )
            
            self.logger.info(f"  ğŸ“Š CLå†…ã§å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°æ•°: {len(changed_functions_in_cl)}")
            if changed_functions_in_cl:
                self.logger.info(f"  ğŸ“Š å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°: {changed_functions_in_cl}")
            
            if not changed_functions_in_cl:
                self.logger.warning(f"  âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {file_path} (å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
                return set()
            
            # 5. ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®å­˜åœ¨ç¢ºèª
            if not self.repo_loader:
                self.logger.warning(f"  âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {file_path} (repo_loaderãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“)")
                return set()
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆæ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰
            directory_files = self._get_files_in_directory(directory_path)
            if not directory_files:
                self.logger.warning(f"  âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {directory_path} (ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“)")
                return set()
            
            self.logger.info(f"  ğŸ“Š ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(directory_files)}")
            self.logger.info(f"  ğŸ“Š ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«: {directory_files[:3]}")
            
            # 6. è©²å½“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§é–¢æ•°åã®ä¸€è‡´ç¢ºèª
            validated_functions = self._validate_functions_in_current_repo(
                changed_functions_in_cl, directory_files, normalized_file_path
            )
            
            self.logger.info(f"  âœ¨ æœ€çµ‚çš„ã«æ¤œå‡ºã•ã‚ŒãŸé–¢æ•°: {len(validated_functions)}å€‹")
            if validated_functions:
                self.logger.info(f"  âœ¨ æ¤œå‡ºã•ã‚ŒãŸé–¢æ•°: {validated_functions}")
            
            return validated_functions
            
        except Exception as e:
            self.logger.error(f"Error in advanced function extraction for {file_path}: {str(e)}")
            import traceback
            self.logger.error(traceback.format_exc())
            return set()
    
    def _get_files_in_directory(self, directory_path: str) -> List[str]:
        """
        ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã®æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Goãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚
        
        Args:
            directory_path: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            
        Returns:
            ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Goãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        try:
            if not self.repo_loader:
                return []
            
            # ãƒªãƒã‚¸ãƒˆãƒªãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰è©²å½“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            all_files = self.repo_loader.get_all_files()
            
            # æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Goãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            directory_files = []
            for file_path in all_files:
                file_dir = '/'.join(file_path.split('/')[:-1]) if '/' in file_path else ''
                if file_dir == directory_path and file_path.endswith('.go'):
                    directory_files.append(file_path)
            
            self.logger.debug(f"  ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {directory_path} å†…ã®Goãƒ•ã‚¡ã‚¤ãƒ«: {len(directory_files)}å€‹")
            return directory_files
            
        except Exception as e:
            self.logger.warning(f"Error getting files in directory {directory_path}: {str(e)}")
            return []
    
    def _validate_functions_in_current_repo(self, changed_functions: Set[str], 
                                          directory_files: List[str], 
                                          original_file_path: str) -> Set[str]:
        """
        ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã§å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã®å­˜åœ¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨é–¢æ•°åã®å®Œå…¨ä¸€è‡´ã®ã¿ã‚’ç¢ºèªã—ã¾ã™ã€‚
        
        Args:
            changed_functions: CLã§å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°åã®ã‚»ãƒƒãƒˆ
            directory_files: ç¢ºèªå¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
            original_file_path: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã«å­˜åœ¨ã™ã‚‹é–¢æ•°åã®ã‚»ãƒƒãƒˆ
        """
        try:
            if not self.repo_loader:
                self.logger.warning("repo_loader is not available")
                return set()
                
            validated_functions = set()
            
            # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            original_file_content = self.repo_loader.get_file_content(original_file_path)
            if original_file_content:
                self.logger.debug(f"  ğŸ“„ å…ƒãƒ•ã‚¡ã‚¤ãƒ« {original_file_path} ãŒç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã«å­˜åœ¨")
                original_functions = self._extract_functions_from_source(original_file_content)
                
                # é–¢æ•°åã®å®Œå…¨ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
                for func_name in changed_functions:
                    if func_name in original_functions:
                        validated_functions.add(func_name)
                        self.logger.info(f"  âœ“ å¤‰æ›´ã‚’æ¤œå‡º: {func_name} (å…ƒãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ç¢ºèª)")
            else:
                self.logger.debug(f"  âš ï¸ å…ƒãƒ•ã‚¡ã‚¤ãƒ« {original_file_path} ãŒç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã«å­˜åœ¨ã—ã¾ã›ã‚“")
            
            return validated_functions
            
        except Exception as e:
            self.logger.error(f"Error validating functions in current repo: {str(e)}")
            return set()
    
    def _get_cl_file_content(self, cl_number: str, file_path: str) -> Optional[str]:
        """
        CLã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—ã—ã¾ã™ã€‚
        
        Args:
            cl_number: CLç•ªå·
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã€ã¾ãŸã¯å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã¯None
        """
        # Gerrit APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        gerrit_endpoints = [
            f"https://go-review.googlesource.com/changes/{cl_number}/revisions/current/files/{urllib.parse.quote_plus(file_path)}/content",
            f"https://go-review.googlesource.com/changes/go~{cl_number}/revisions/current/files/{urllib.parse.quote_plus(file_path)}/content"
        ]
        
        headers = {'Accept': 'text/plain'}
        max_retries = 3  # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
        retry_delay = 2  # åŸºæœ¬ãƒªãƒˆãƒ©ã‚¤å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
        
        for endpoint in gerrit_endpoints:
            for attempt in range(max_retries):
                try:
                    response = requests.get(endpoint, headers=headers, timeout=30)
                    if response.status_code == 200:
                        content = response.text
                        if self._is_base64(content):
                            try:
                                decoded = base64.b64decode(content).decode('utf-8')
                                return decoded
                            except (binascii.Error, UnicodeDecodeError) as e:
                                self.logger.warning(f"Base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
                                continue
                        return content
                    elif response.status_code == 404:
                        # 404ã®å ´åˆã¯æ¬¡ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦ã™
                        break
                    elif response.status_code == 429:  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã¯é•·ã‚ã«å¾…æ©Ÿ
                        wait_time = retry_delay * (5 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                        self.logger.warning(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
                        time.sleep(wait_time)
                        continue
                    else:
                        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒªãƒˆãƒ©ã‚¤
                        wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                        self.logger.warning(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}ï¼‰ã€‚{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ã€‚")
                        time.sleep(wait_time)
                        continue
                except requests.exceptions.Timeout:
                    wait_time = retry_delay * (2 ** attempt)
                    self.logger.warning(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ã€‚")
                    if attempt < max_retries - 1:
                        time.sleep(wait_time)
                        continue
                except requests.exceptions.RequestException as e:
                    wait_time = retry_delay * (2 ** attempt)
                    self.logger.warning(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆ{attempt + 1}/{max_retries}ï¼‰: {str(e)}")
                    if attempt < max_retries - 1:
                        time.sleep(wait_time)
                        continue
        
        return None

    def _get_file_diff_content(self, cl_number: str, file_path: str) -> Optional[Dict]:
        """
        diffæƒ…å ±ã‹ã‚‰å¤‰æ›´ã•ã‚ŒãŸè¡Œã®å†…å®¹ã‚’å–å¾—ã—ã¾ã™ã€‚
        
        Returns:
            {
                'changed_line_contents': Set[str],  # å¤‰æ›´ã•ã‚ŒãŸè¡Œã®å†…å®¹ã®ã‚»ãƒƒãƒˆ
                'added_line_contents': Set[str],    # è¿½åŠ ã•ã‚ŒãŸè¡Œã®å†…å®¹ã®ã‚»ãƒƒãƒˆ
                'deleted_line_contents': Set[str]   # å‰Šé™¤ã•ã‚ŒãŸè¡Œã®å†…å®¹ã®ã‚»ãƒƒãƒˆ
            }
        """
        gerrit_endpoints = [
            f"https://go-review.googlesource.com/changes/{cl_number}/revisions/current/files/{urllib.parse.quote_plus(file_path)}/diff",
            f"https://go-review.googlesource.com/changes/go~{cl_number}/revisions/current/files/{urllib.parse.quote_plus(file_path)}/diff"
        ]
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; GoProposalAnalyzer/1.0)',
            'Accept': 'application/json',
        }
        
        for endpoint in gerrit_endpoints:
            try:
                response = requests.get(endpoint, headers=headers, timeout=30)
                if response.status_code == 200:
                    text = response.text
                    if text.startswith(")]}'"):
                        text = text[4:]
                    
                    try:
                        diff_data = json.loads(text)
                        
                        changed_line_contents = set()
                        added_line_contents = set()
                        deleted_line_contents = set()
                        
                        # Gerrit diffå½¢å¼ã®è§£æ
                        if 'content' in diff_data:
                            for content_item in diff_data['content']:
                                # è¿½åŠ ã•ã‚ŒãŸè¡Œã®å†…å®¹ (å³å´ã®å¤‰æ›´)
                                if 'b' in content_item:
                                    for line_content in content_item['b']:
                                        line_stripped = line_content.strip()
                                        if line_stripped:  # ç©ºè¡Œã‚’é™¤å¤–
                                            added_line_contents.add(line_stripped)
                                            changed_line_contents.add(line_stripped)
                                
                                # å‰Šé™¤ã•ã‚ŒãŸè¡Œã®å†…å®¹ (å·¦å´ã®å¤‰æ›´)
                                if 'a' in content_item:
                                    for line_content in content_item['a']:
                                        line_stripped = line_content.strip()
                                        if line_stripped:  # ç©ºè¡Œã‚’é™¤å¤–
                                            deleted_line_contents.add(line_stripped)
                                            changed_line_contents.add(line_stripped)
                                
                                # å¤‰æ›´ãªã—ã®è¡Œï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã¯é™¤å¤–
                                # 'ab'ã¯ä¸¡å´ã«å­˜åœ¨ã™ã‚‹è¡Œãªã®ã§ã€å¤‰æ›´ã•ã‚Œã¦ã„ãªã„
                        
                        self.logger.debug(f"Diff analysis for {file_path}: "
                                   f"added={len(added_line_contents)}, "
                                   f"deleted={len(deleted_line_contents)}, "
                                   f"total_changed={len(changed_line_contents)}")
                        
                        return {
                            'changed_line_contents': changed_line_contents,
                            'added_line_contents': added_line_contents,
                            'deleted_line_contents': deleted_line_contents
                        }
                    except json.JSONDecodeError as e:
                        self.logger.warning(f"JSON decode error for {endpoint}: {str(e)}")
                        continue
                elif response.status_code == 404:
                    self.logger.debug(f"Diff not found for {file_path} in CL {cl_number}")
                    break
                else:
                    self.logger.warning(f"Unexpected status code {response.status_code} for {endpoint}")
            except requests.exceptions.RequestException as e:
                self.logger.warning(f"Request failed for {endpoint}: {str(e)}")
                continue
        
        # Fallback: GitHub APIã‚’ä½¿ç”¨ã—ã¦diffæƒ…å ±ã‚’å–å¾—
        return self._get_github_diff_content(cl_number, file_path)
    
    def _get_github_diff_content(self, cl_number: str, file_path: str) -> Optional[Dict]:
        """
        GitHub APIã‚’ä½¿ç”¨ã—ã¦diffæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ã€‚
        """
        try:
            # GitHubã®commit APIã‚’ä½¿ç”¨
            github_url = f"https://api.github.com/repos/golang/go/commits"
            headers = {
                'User-Agent': 'Mozilla/5.0 (compatible; GoProposalAnalyzer/1.0)',
                'Accept': 'application/vnd.github.v3+json',
            }
            
            # CLç•ªå·ã‹ã‚‰commit hashã‚’æ¤œç´¢ï¼ˆç°¡ç•¥åŒ–ï¼‰
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€CLç•ªå·ã¨commit hashã®ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå¿…è¦
            
            # ç›´æ¥çš„ãªdiffå–å¾—ã‚’è©¦è¡Œ
            raw_github_url = f"https://raw.githubusercontent.com/golang/go/HEAD/{file_path}"
            response = requests.get(raw_github_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—ã§ããŸå ´åˆã€
                # ç°¡å˜ãªè¡Œãƒ™ãƒ¼ã‚¹ã®æ¯”è¼ƒã‚’è¡Œã†
                current_content = response.text
                
                # CLã®å†…å®¹ã¨æ¯”è¼ƒ
                cl_content = self._get_cl_file_content(cl_number, file_path)
                if cl_content:
                    return self._compare_file_contents(current_content, cl_content)
            
        except Exception as e:
            self.logger.warning(f"GitHub fallback failed: {str(e)}")
        
        return None
    
    def _compare_file_contents(self, content1: str, content2: str) -> Dict:
        """
        2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’æ¯”è¼ƒã—ã¦diffæƒ…å ±ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
        """
        try:
            lines1 = content1.splitlines()
            lines2 = content2.splitlines()
            
            added_line_contents = set()
            deleted_line_contents = set()
            changed_line_contents = set()
            
            # ç°¡å˜ãªdiffå®Ÿè£…
            lines1_set = set(line.strip() for line in lines1 if line.strip())
            lines2_set = set(line.strip() for line in lines2 if line.strip())
            
            # è¿½åŠ ã•ã‚ŒãŸè¡Œ
            for line in lines2_set - lines1_set:
                added_line_contents.add(line)
                changed_line_contents.add(line)
            
            # å‰Šé™¤ã•ã‚ŒãŸè¡Œ
            for line in lines1_set - lines2_set:
                deleted_line_contents.add(line)
                changed_line_contents.add(line)
            
            return {
                'changed_line_contents': changed_line_contents,
                'added_line_contents': added_line_contents,
                'deleted_line_contents': deleted_line_contents
            }
            
        except Exception as e:
            self.logger.error(f"Error comparing file contents: {str(e)}")
            return {
                'changed_line_contents': set(),
                'added_line_contents': set(),
                'deleted_line_contents': set()
            }

    def _find_changed_functions_by_content_matching(self, cl_content: str, cl_functions: Dict[str, Tuple[int, int]], diff_info: Dict) -> Set[str]:
        """
        diffæƒ…å ±ã¨é–¢æ•°ã®å†…å®¹ã‚’æ¯”è¼ƒã—ã¦ã€å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã‚’ç‰¹å®šã—ã¾ã™ã€‚
        1. å¤‰æ›´ã•ã‚ŒãŸè¡ŒãŒé–¢æ•°å†…ã«å­˜åœ¨ã™ã‚‹ã‹ã‚’ç¢ºèª
        2. é–¢æ•°ã®å†…å®¹å…¨ä½“ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèª
        
        Args:
            cl_content: CLã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
            cl_functions: CLã®ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®é–¢æ•°æƒ…å ±ï¼ˆé–¢æ•°å -> (é–‹å§‹è¡Œ, çµ‚äº†è¡Œ)ï¼‰
            diff_info: diffæƒ…å ±
            
        Returns:
            å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°åã®ã‚»ãƒƒãƒˆ
        """
        try:
            changed_functions = set()
            changed_lines = diff_info.get('changed_line_contents', set())
            
            # å„é–¢æ•°ã«ã¤ã„ã¦å¤‰æ›´ã‚’ç¢ºèª
            for func_name, (start_line, end_line) in cl_functions.items():
                # é–¢æ•°ã®å†…å®¹ã‚’å–å¾—
                func_lines = cl_content.splitlines()[start_line - 1:end_line]
                func_content = set(line.strip() for line in func_lines if line.strip())
                
                # 1. å¤‰æ›´ã•ã‚ŒãŸè¡ŒãŒé–¢æ•°å†…ã«å­˜åœ¨ã™ã‚‹ã‹ã‚’ç¢ºèª
                for changed_line in changed_lines:
                    if changed_line.strip() in func_content:
                        changed_functions.add(func_name)
                        self.logger.debug(f"  âœ“ é–¢æ•°å†…ã®è¡Œå¤‰æ›´ã‚’æ¤œå‡º: {func_name}")
                        break
                
                # 2. é–¢æ•°ã®å†…å®¹å…¨ä½“ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèª
                if func_name not in changed_functions:  # ã¾ã å¤‰æ›´ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¦ã„ãªã„å ´åˆ
                    func_content_str = '\n'.join(func_lines)
                    if func_content_str in changed_lines:
                        changed_functions.add(func_name)
                        self.logger.debug(f"  âœ“ é–¢æ•°ã®å†…å®¹å¤‰æ›´ã‚’æ¤œå‡º: {func_name}")
            
            return changed_functions
            
        except Exception as e:
            self.logger.error(f"Error in content matching: {str(e)}")
            return set()

    def _extract_functions_from_source(self, source_code: str) -> Dict[str, Tuple[int, int]]:
        """
        ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é–¢æ•°ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã™ï¼ˆtree-sitterã‚’ä½¿ç”¨ï¼‰ã€‚
        """
        try:
            if not self.parser or not self.go_language:
                self.logger.error("Tree-sitter parser not available")
                return {}
            
            tree = self.parser.parse(source_code.encode('utf-8'))
            functions = {}
            
            def visit_node(node):
                if node.type == 'function_declaration':
                    # é–¢æ•°åã‚’å–å¾—
                    name_node = self._find_child_by_type(node, 'identifier')
                    if name_node:
                        func_name = source_code[name_node.start_byte:name_node.end_byte]
                        start_line = node.start_point[0] + 1
                        end_line = node.end_point[0] + 1
                        functions[func_name] = (start_line, end_line)
                        self.logger.debug(f"Found function: {func_name} ({start_line}-{end_line})")
                
                elif node.type == 'method_declaration':
                    # ãƒ¡ã‚½ãƒƒãƒ‰åã‚’å–å¾—
                    name_node = self._find_child_by_type(node, 'field_identifier')
                    if name_node:
                        method_name = source_code[name_node.start_byte:name_node.end_byte]
                        start_line = node.start_point[0] + 1
                        end_line = node.end_point[0] + 1
                        functions[method_name] = (start_line, end_line)
                        self.logger.debug(f"Found method: {method_name} ({start_line}-{end_line})")
                
                # å­ãƒãƒ¼ãƒ‰ã‚’å†å¸°çš„ã«å‡¦ç†
                for child in node.children:
                    visit_node(child)
            
            visit_node(tree.root_node)
            return functions
            
        except Exception as e:
            self.logger.error(f"Error in function extraction: {str(e)}")
            return {}
    
    def _find_child_by_type(self, node, node_type: str):
        """æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ã®æœ€åˆã®å­ãƒãƒ¼ãƒ‰ã‚’æ¤œç´¢"""
        for child in node.children:
            if child.type == node_type:
                return child
        return None

    def fetch_changes_from_proposal(self, proposal_content: str) -> Optional[Dict]:
        """
        ææ¡ˆã‹ã‚‰CLã®å¤‰æ›´ã‚’å–å¾—ã—ã¾ã™ï¼ˆå¾“æ¥ã®CLChangeFetcherã¨ã®äº’æ›æ€§ã®ãŸã‚ï¼‰
        """
        try:
            # å¾“æ¥ã®CLChangeFetcherã‚’ä½¿ã£ã¦åŸºæœ¬æƒ…å ±ã‚’å–å¾—
            from scripts.cl_change_fetcher import CLChangeFetcher
            legacy_fetcher = CLChangeFetcher()
            
            # åŸºæœ¬çš„ãªCLæƒ…å ±ã‚’å–å¾—
            basic_changes = legacy_fetcher.fetch_changes_from_proposal(proposal_content)
            if not basic_changes:
                self.logger.warning("åŸºæœ¬çš„ãªCLæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return None
            
            cl_number = basic_changes.get('cl_number', '')
            self.logger.info(f"ğŸ” CL {cl_number} ã®æ”¹è‰¯ç‰ˆè§£æã‚’é–‹å§‹")
            
            # æ”¹è‰¯ç‰ˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§é–¢æ•°å¤‰æ›´ã‚’æ¤œå‡º
            enhanced_changes = basic_changes.copy()
            files = basic_changes.get('files', {})
            
            total_files = len([f for f in files.keys() if f.endswith('.go')])
            processed_files = 0
            total_functions_detected = 0
            
            self.logger.info(f"ğŸ“‚ å‡¦ç†å¯¾è±¡Goãƒ•ã‚¡ã‚¤ãƒ«: {total_files}å€‹")
            
            for file_path, file_info in files.items():
                if file_path.endswith('.go'):
                    self.logger.info(f"ğŸ”„ æ”¹è‰¯ç‰ˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å‡¦ç†ä¸­: {file_path}")
                    
                    # æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§é–¢æ•°å¤‰æ›´ã‚’æ¤œå‡º
                    changed_functions = self.extract_changed_functions_advanced(
                        cl_number, file_path
                    )
                    
                    # çµæœã‚’æ›´æ–°
                    enhanced_changes['files'][file_path]['modified_functions'] = list(changed_functions)
                    
                    processed_files += 1
                    function_count = len(changed_functions)
                    total_functions_detected += function_count
                    
                    if function_count > 0:
                        self.logger.info(f"  âœ… {file_path}: {function_count}å€‹ã®é–¢æ•°å¤‰æ›´ã‚’æ¤œå‡º")
                        # é–¢æ•°åã‚’è¡¨ç¤ºï¼ˆæœ€å¤§5å€‹ã¾ã§ï¼‰
                        func_names = list(changed_functions)[:5]
                        self.logger.info(f"    é–¢æ•°: {', '.join(func_names)}" + 
                                  (f" (+{function_count-5}å€‹)" if function_count > 5 else ""))
                    else:
                        self.logger.info(f"  âšª {file_path}: é–¢æ•°å¤‰æ›´ãªã—")
            
            # çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›
            self.logger.info(f"ğŸ“Š CL {cl_number} è§£æå®Œäº†:")
            self.logger.info(f"  - å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {processed_files}/{total_files}")
            self.logger.info(f"  - æ¤œå‡ºé–¢æ•°æ•°: {total_functions_detected}å€‹")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            enhanced_changes['analysis_metadata'] = {
                'processed_files': processed_files,
                'total_go_files': total_files,
                'total_functions_detected': total_functions_detected,
                'analysis_method': 'improved_content_matching'
            }
            
            return enhanced_changes
            
        except Exception as e:
            self.logger.error(f"Error in fetch_changes_from_proposal: {str(e)}")
            return None

    def _is_base64(self, content: str) -> bool:
        """æ–‡å­—åˆ—ãŒbase64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¾ã™"""
        if not content:
            return False
        try:
            return bool(re.match(r'^[A-Za-z0-9+/]*={0,2}$', content))
        except TypeError:
            return False

    def _get_cl_info(self, cl_number: str) -> Optional[Dict[str, Any]]:
        """
        CLã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚
        è¤‡æ•°ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦ã—ã€ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚ŒãŸCLã«ã‚‚å¯¾å¿œã—ã¾ã™ã€‚
        
        Args:
            cl_number: CLç•ªå·
            
        Returns:
            CLæƒ…å ±ã‚’å«ã‚€è¾æ›¸ã€ã¾ãŸã¯å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã¯None
        """
        endpoints = [
            # æ¨™æº–çš„ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            f"https://go-review.googlesource.com/changes/{cl_number}",
            f"https://go-review.googlesource.com/changes/go~{cl_number}",
            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚ŒãŸCLç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            f"https://go-review.googlesource.com/changes/{cl_number}?o=ALL_REVISIONS",
            f"https://go-review.googlesource.com/changes/go~{cl_number}?o=ALL_REVISIONS",
            # å¤ã„CLç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            f"https://go-review.googlesource.com/changes/{cl_number}?o=ALL_REVISIONS&o=DETAILED_ACCOUNTS",
            f"https://go-review.googlesource.com/changes/go~{cl_number}?o=ALL_REVISIONS&o=DETAILED_ACCOUNTS"
        ]
        
        headers = {
            'Accept': 'application/json',
            'User-Agent': 'CLChangeFetcher/1.0'
        }
        
        max_retries = 5
        initial_retry_delay = 2
        max_retry_delay = 60
        
        for endpoint in endpoints:
            self.logger.info(f"ğŸ” Trying endpoint for CL info: {endpoint}")
            
            for attempt in range(max_retries):
                try:
                    retry_delay = min(initial_retry_delay * (2 ** attempt), max_retry_delay)
                    
                    response = requests.get(endpoint, headers=headers, timeout=30)
                    self.logger.debug(f"Response status: {response.status_code}")
                    
                    if response.status_code == 200:
                        content = response.text
                        if content.startswith(")]}'"):
                            content = content[4:]
                        try:
                            data = json.loads(content)
                            if data:
                                # CLã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
                                status = data.get('status', '')
                                if status == 'ABANDONED':
                                    self.logger.warning(f"CL {cl_number} is abandoned")
                                elif status == 'MERGED':
                                    self.logger.info(f"CL {cl_number} is merged")
                                
                                self.logger.info(f"âœ… Successfully fetched CL info from {endpoint}")
                                self.logger.info(f"CL Subject: {data.get('subject', 'N/A')}")
                                return data
                            else:
                                self.logger.warning(f"Empty response from {endpoint}")
                        except json.JSONDecodeError as je:
                            self.logger.warning(f"Invalid JSON response from {endpoint}: {str(je)}")
                            self.logger.debug(f"Response content: {content[:200]}...")
                    
                    elif response.status_code == 404:
                        self.logger.info(f"CL not found at {endpoint}")
                        break
                    
                    elif response.status_code == 429:
                        retry_after = int(response.headers.get('Retry-After', retry_delay))
                        self.logger.warning(f"Rate limit hit. Waiting {retry_after} seconds...")
                        time.sleep(retry_after)
                        continue
                    
                    elif response.status_code == 401:
                        self.logger.warning(f"Authentication required for {endpoint}")
                        break
                    
                    elif response.status_code == 410:
                        self.logger.warning(f"CL is gone (possibly archived) at {endpoint}")
                        continue
                    
                    else:
                        self.logger.warning(f"Unexpected status code {response.status_code} from {endpoint}")
                        if attempt < max_retries - 1:
                            self.logger.info(f"Retrying in {retry_delay} seconds...")
                            time.sleep(retry_delay)
                        continue
                
                except requests.exceptions.Timeout:
                    self.logger.warning(f"Timeout accessing {endpoint}")
                    if attempt < max_retries - 1:
                        self.logger.info(f"Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                    continue
                
                except requests.exceptions.RequestException as e:
                    self.logger.warning(f"Network error accessing {endpoint}: {str(e)}")
                    if attempt < max_retries - 1:
                        self.logger.info(f"Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                    continue
        
        self.logger.error(f"âŒ Failed to fetch CL info for {cl_number} from all endpoints")
        return None

    def _get_file_changes(self, cl_number: str) -> Optional[Dict[str, Any]]:
        """
        CLã®ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚
        è¤‡æ•°ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦ã—ã€ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚ŒãŸCLã«ã‚‚å¯¾å¿œã—ã¾ã™ã€‚
        
        Args:
            cl_number: CLç•ªå·
            
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æƒ…å ±ã‚’å«ã‚€è¾æ›¸ã€ã¾ãŸã¯å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã¯None
        """
        endpoints = [
            # æ¨™æº–çš„ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            f"https://go-review.googlesource.com/changes/{cl_number}/revisions/current/files",
            f"https://go-review.googlesource.com/changes/go~{cl_number}/revisions/current/files",
            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚ŒãŸCLç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            f"https://go-review.googlesource.com/changes/{cl_number}/revisions/current/files?o=ALL_FILES",
            f"https://go-review.googlesource.com/changes/go~{cl_number}/revisions/current/files?o=ALL_FILES",
            # å¤ã„CLç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            f"https://go-review.googlesource.com/changes/{cl_number}/revisions/1/files",
            f"https://go-review.googlesource.com/changes/go~{cl_number}/revisions/1/files"
        ]
        
        headers = {
            'Accept': 'application/json',
            'User-Agent': 'CLChangeFetcher/1.0'
        }
        
        max_retries = 5  # ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’å¢—ã‚„ã™
        initial_retry_delay = 2
        max_retry_delay = 60  # æœ€å¤§å¾…æ©Ÿæ™‚é–“ã‚’60ç§’ã«è¨­å®š
        
        for endpoint in endpoints:
            self.logger.info(f"ğŸ” Trying endpoint: {endpoint}")
            
            for attempt in range(max_retries):
                try:
                    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã«ã‚ˆã‚‹å¾…æ©Ÿæ™‚é–“ã®è¨ˆç®—
                    retry_delay = min(initial_retry_delay * (2 ** attempt), max_retry_delay)
                    
                    response = requests.get(endpoint, headers=headers, timeout=30)
                    self.logger.debug(f"Response status: {response.status_code}")
                    
                    if response.status_code == 200:
                        # Gerrit APIã¯)]}'ã§å§‹ã¾ã‚‹ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ãŸã‚ã€ãã‚Œã‚’é™¤å»
                        content = response.text
                        if content.startswith(")]}'"):
                            content = content[4:]
                        try:
                            data = json.loads(content)
                            if data:
                                self.logger.info(f"âœ… Successfully fetched file changes from {endpoint}")
                                return data
                            else:
                                self.logger.warning(f"Empty response from {endpoint}")
                        except json.JSONDecodeError as je:
                            self.logger.warning(f"Invalid JSON response from {endpoint}: {str(je)}")
                            self.logger.debug(f"Response content: {content[:200]}...")
                    
                    elif response.status_code == 404:
                        self.logger.info(f"CL not found at {endpoint}")
                        break  # æ¬¡ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦ã™
                    
                    elif response.status_code == 429:  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                        retry_after = int(response.headers.get('Retry-After', retry_delay))
                        self.logger.warning(f"Rate limit hit. Waiting {retry_after} seconds...")
                        time.sleep(retry_after)
                        continue
                    
                    elif response.status_code == 401:
                        self.logger.warning(f"Authentication required for {endpoint}")
                        break  # èªè¨¼ãŒå¿…è¦ãªå ´åˆã¯æ¬¡ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦ã™
                    
                    elif response.status_code == 410:
                        self.logger.warning(f"CL is gone (possibly archived) at {endpoint}")
                        continue  # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§æ¬¡ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦ã™
                    
                    else:
                        self.logger.warning(f"Unexpected status code {response.status_code} from {endpoint}")
                        if attempt < max_retries - 1:
                            self.logger.info(f"Retrying in {retry_delay} seconds...")
                            time.sleep(retry_delay)
                        continue
                
                except requests.exceptions.Timeout:
                    self.logger.warning(f"Timeout accessing {endpoint}")
                    if attempt < max_retries - 1:
                        self.logger.info(f"Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                    continue
                
                except requests.exceptions.RequestException as e:
                    self.logger.warning(f"Network error accessing {endpoint}: {str(e)}")
                    if attempt < max_retries - 1:
                        self.logger.info(f"Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                    continue
        
        self.logger.error(f"âŒ Failed to fetch file changes for CL {cl_number} from all endpoints")
        return None

if __name__ == '__main__':
    # ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®CLç•ªå·ã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    test_cl = "458335"  # ä»¥å‰æˆåŠŸã—ãŸCLã‚’ä½¿ç”¨
    test_file = "src/runtime/exec_freebsd.go"
    
    # ãƒªãƒã‚¸ãƒˆãƒªãƒ­ãƒ¼ãƒ€ãƒ¼ã¨ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã®åˆæœŸåŒ–
    repo_loader = SimpleRepoLoader(".")
    fetcher = ImprovedCLChangeFetcher(repo_loader)
    
    # å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã‚’å–å¾—
    changed_functions = fetcher.extract_changed_functions_advanced(test_cl, test_file)
    
    # çµæœã‚’è¡¨ç¤º
    print("\n=== æ¤œå‡ºã•ã‚ŒãŸå¤‰æ›´é–¢æ•° ===")
    for func in sorted(changed_functions):
        print(f"âœ“ {func}") 