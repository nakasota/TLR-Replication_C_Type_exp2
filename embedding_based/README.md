# Embedding-Based Bug Localization

This directory contains tools for generating embeddings from source code and performing embedding-based bug localization using OpenAI's embedding models.

## Overview

The embedding-based approach works in two main steps:
1. **Embedding Generation**: Create vector embeddings for all files and functions in the codebase
2. **Bug Localization**: Use cosine similarity to find the most relevant code locations for bug reports

## Main Components

### 1. Embedding Generation (`embedding_creator_for_file_and_func.py`)

Generates embeddings for both files and functions using OpenAI's `text-embedding-3-large` model.

**Input:**
- `../data/preprocess/go_repo_structure.json` - Preprocessed Go repository structure

**Output:**
- `embeddings_cache_openai/file_embeddings.pkl` - File-level embeddings
- `embeddings_cache_openai/file_paths.pkl` - Corresponding file paths
- `embeddings_cache_openai/function_embeddings.pkl` - Function-level embeddings  
- `embeddings_cache_openai/function_identifiers.pkl` - Function identifiers (file_path, function_name)

**Features:**
- No content truncation - full file and function content is embedded
- Batch processing (1000 items per batch) for efficiency
- Progress tracking and error handling
- Automatic rate limiting for OpenAI API

### 2. Bug Localization (`embedding_based_localization_full.py`)

Performs comprehensive multi-granularity evaluation of bug localization effectiveness.

**Input:**
- Embedding files generated by `embedding_creator_for_file_and_func.py`
- `../data/preprocess/accepted_proposals/cleaned_evaluable_proposals/` - Bug reports/proposals

**Output:**
- Timestamped directory with evaluation results
- Precision/Recall/F1 plots for different granularities
- Comprehensive markdown evaluation report

**Evaluation Granularities:**
- **Directory Level**: Groups files by directory structure
- **File Level**: Individual file matching
- **Function Level**: Individual function matching

**Metrics:**
- Precision, Recall, F1-score
- Top-k evaluation (k = 5, 10, 20, 30, 40, 50)
- Multi-granularity comparison

## Setup

### Prerequisites

1. **OpenAI API Key**: Set your OpenAI API key in the project root `.env` file:
   ```
   OPENAI_API_KEY=your_api_key_here
   ```

2. **Required Python Packages**: Install dependencies from the project root:
   ```bash
   pip install -r requirements.txt
   ```

3. **Preprocessed Data**: Ensure the Go repository structure has been preprocessed:
   ```
   data/preprocess/go_repo_structure.json
   ```

### Usage

#### Step 1: Generate Embeddings

```bash
cd embedding_based
python embedding_creator_for_file_and_func.py
```

This will:
- Load the preprocessed repository structure
- Generate embeddings for ~10,605 files and ~85,800 functions
- Save embeddings to `embeddings_cache_openai/`
- Display progress and statistics

**Expected Output:**
```
ğŸ“ Total files: 10605
ğŸ”§ Total functions: 85800
ğŸ¤– Loading embedding model: text-embedding-3-large
ğŸ”„ Embedding items 1-1000 of 10605...
...
ğŸ’¾ Saved embeddings to embeddings_cache_openai/
```

#### Step 2: Run Bug Localization Evaluation

```bash
python embedding_based_localization_full.py
```

This will:
- Load the generated embeddings
- Process all bug reports/proposals
- Compute similarities and rankings
- Generate evaluation plots and reports
- Save results to timestamped output directory

**Expected Output:**
```
ğŸ“‚ Loading embeddings from embeddings_cache_openai/
ğŸ“‹ Processing 123 proposals...
ğŸ“Š Evaluating at multiple granularities...
ğŸ’¾ Results saved to output/YYYYMMDD_HHMMSS_openai_text-embedding-3-large/
```

## Cost Estimation

Using OpenAI's `text-embedding-3-large` model (pricing as of 2024):
- **Rate**: $0.00013 per 1K tokens
- **Estimated cost**: ~$50-100 for full repository embedding
- **Factors**: File sizes, function lengths, total content volume

Use the built-in cost estimation:
```python
from openai_embedding_utils import estimate_cost
cost = estimate_cost(num_texts=10000, avg_tokens_per_text=500)
print(f"Estimated cost: ${cost:.2f}")
```

## Technical Details

### Embedding Model
- **Model**: `text-embedding-3-large`
- **Dimensions**: 3072
- **Max tokens**: 8,191 per input
- **Context**: Full file/function content (no truncation)

### File Processing
Files are embedded as:
```
File: {file_path} Content: {full_file_content}
```

### Function Processing
Functions are embedded as:
```
Function: {function_name} File: {file_path} Code: {full_function_body}
```

### Similarity Computation
- **Method**: Cosine similarity
- **Ranking**: Descending similarity scores
- **Evaluation**: Top-k precision/recall across multiple k values

## Output Structure

```
output/
â”œâ”€â”€ YYYYMMDD_HHMMSS_openai_text-embedding-3-large/
â”‚   â”œâ”€â”€ evaluation_summary.md
â”‚   â”œâ”€â”€ precision.png
â”‚   â”œâ”€â”€ recall.png
â”‚   â””â”€â”€ f1.png
â””â”€â”€ ...

embeddings_cache_openai/
â”œâ”€â”€ file_embeddings.pkl
â”œâ”€â”€ file_paths.pkl
â”œâ”€â”€ function_embeddings.pkl
â””â”€â”€ function_identifiers.pkl
```

## Troubleshooting

### Common Issues

1. **API Key Error**: Ensure OPENAI_API_KEY is set in `.env` file
2. **Memory Issues**: Large repositories may require more RAM for embedding storage
3. **Rate Limiting**: Built-in delays handle OpenAI rate limits automatically
4. **Token Limits**: Very large files may exceed 8,191 token limit (rare)

### Debug Mode

Enable detailed logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## Performance

### Expected Runtime
- **Embedding Generation**: 2-4 hours for full Go repository
- **Bug Localization**: 10-30 minutes depending on number of proposals
- **Total**: ~3-5 hours for complete pipeline

### Optimization
- Embeddings are cached and reused
- Batch processing minimizes API calls
- Progress tracking for long-running operations

## Related Files

- `openai_embedding_utils.py` - OpenAI API wrapper and utilities
- `../data/preprocess/go_repo_structure.json` - Source repository data
- `../requirements.txt` - Python dependencies
- `../.env` - Environment variables (API keys)
