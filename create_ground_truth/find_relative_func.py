#!/usr/bin/env python3
"""
æ‹¡å¼µCLã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼: mdãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰CLç•ªå·ã‚’æŠ½å‡ºã—ã€å·®åˆ†è¡Œç•ªå·ã‚’å–å¾—ã€
ASTè§£æã«ã‚ˆã£ã¦å¤‰æ›´ãŒå±ã™ã‚‹é–¢æ•°ã‚’ç‰¹å®šã™ã‚‹
"""

import re
import json
import requests
import time
import logging
import argparse
import base64
import sys
import os
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path

# tree-sitterã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append('/workspace/tree-sitter-build/lib')

try:
    import tree_sitter as ts
    TREE_SITTER_AVAILABLE = True
except ImportError:
    TREE_SITTER_AVAILABLE = False
    print("âš ï¸ tree-sitterãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ASTè§£æã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")

# ãƒ­ã‚°è¨­å®š
def log_info(msg):
    print(f"[INFO] {msg}")
def log_debug(msg):
    print(f"[DEBUG] {msg}")
def log_warning(msg):
    print(f"[WARNING] {msg}")
def log_error(msg):
    print(f"[ERROR] {msg}")

class EnhancedCLAnalyzer:
    """æ‹¡å¼µã•ã‚ŒãŸCLã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼: å·®åˆ†è¡Œã¨ASTè§£ææ©Ÿèƒ½ä»˜ã"""
    
    GERRIT_API_BASE = "https://go-review.googlesource.com"
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Enhanced-CL-Analyzer/1.0'
        })
        
        # tree-sitterãƒ‘ãƒ¼ã‚µãƒ¼ã®åˆæœŸåŒ–
        self.go_parser = None
        if TREE_SITTER_AVAILABLE:
            self._init_tree_sitter()
    
    def _init_tree_sitter(self):
        """tree-sitter Go ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆæœŸåŒ–"""
        try:
            # Goãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ‘ã‚¹
            go_lib_path = '/workspace/tree-sitter-build/lib/go.so'
            if not os.path.exists(go_lib_path):
                log_warning(f"Goãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {go_lib_path}")
                return
            
            # ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆæœŸåŒ–
            GO_LANGUAGE = ts.Language(go_lib_path, 'go')
            self.go_parser = ts.Parser()
            self.go_parser.set_language(GO_LANGUAGE)
            log_info("âœ“ tree-sitter Goãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆæœŸåŒ–")
            
        except Exception as e:
            log_error(f"tree-sitteråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.go_parser = None
    
    def analyze_proposal(self, proposal_file_path: str) -> Dict[str, Any]:
        """ææ¡ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰CLã‚’æŠ½å‡ºã—ã€å·®åˆ†è¡Œã¨ASTè§£æã‚’å®Ÿè¡Œ"""
        log_info(f"æ‹¡å¼µè§£æé–‹å§‹: {proposal_file_path}")
        
        # 1. mdãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰CLç•ªå·ã‚’æŠ½å‡º
        content = self._read_file(proposal_file_path)
        if not content:
            return {'error': f'ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {proposal_file_path}'}
        
        cl_numbers = self._extract_cl_numbers(content)
        if not cl_numbers:
            return {'error': f'CLç•ªå·ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {proposal_file_path}'}
        
        log_info(f"âœ“ {len(cl_numbers)}å€‹ã®CLç•ªå·ã‚’æ¤œå‡º: {cl_numbers}")
        
        # 2. å„CLã®è©³ç´°è§£æ
        cl_analyses = []
        
        for cl_number in cl_numbers:
            log_info(f"CL {cl_number} ã®è©³ç´°è§£æä¸­...")
            
            cl_analysis = self._analyze_cl_detailed(cl_number)
            if cl_analysis:
                cl_analyses.append(cl_analysis)
                log_info(f"âœ“ CL {cl_number}: {len(cl_analysis.get('files', []))}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ")
            else:
                log_warning(f"âš ï¸ CL {cl_number}: è§£æå¤±æ•—")
            
            # APIåˆ¶é™å¯¾ç­–
            time.sleep(0.5)
        
        result = {
            'proposal_file': proposal_file_path,
            'cl_numbers': cl_numbers,
            'total_cls_analyzed': len(cl_analyses),
            'cl_analyses': cl_analyses,
            'tree_sitter_enabled': TREE_SITTER_AVAILABLE and self.go_parser is not None
        }
        
        log_info(f"âœ“ å®Œäº†: {len(cl_analyses)}å€‹ã®CLã‚’è©³ç´°è§£æ")
        return result
    
    def _analyze_cl_detailed(self, cl_number: str) -> Optional[Dict[str, Any]]:
        """CLã®è©³ç´°è§£æ: åŸºæœ¬æƒ…å ±ã€diffã€ASTè§£æ"""
        try:
            # 1. CLåŸºæœ¬æƒ…å ±ã‚’å–å¾—
            basic_info = self._fetch_cl_info(cl_number)
            if not basic_info:
                return None
            
            # 2. å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            changed_files = self._fetch_file_list(cl_number)
            if not changed_files:
                return None
            
            # 3. å„ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°è§£æ
            file_analyses = []
            current_revision = basic_info.get('current_revision')
            
            if current_revision:
                for file_path, file_info in changed_files.items():
                    if file_path == '/COMMIT_MSG':
                        continue
                    
                    # Goãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
                    if not file_path.endswith('.go'):
                        continue
                    
                    file_analysis = self._analyze_file_detailed(
                        cl_number, file_path, file_info, current_revision
                    )
                    
                    if file_analysis:
                        file_analyses.append(file_analysis)
            
            return {
                'cl_number': cl_number,
                'subject': basic_info.get('subject', ''),
                'status': basic_info.get('status', ''),
                'current_revision': current_revision,
                'total_files_changed': len([f for f in changed_files.keys() if f != '/COMMIT_MSG']),
                'go_files_analyzed': len(file_analyses),
                'files': file_analyses
            }
            
        except Exception as e:
            log_error(f"CL {cl_number} è©³ç´°è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _analyze_file_detailed(self, cl_number: str, file_path: str, 
                               file_info: Dict[str, Any], revision_id: str) -> Optional[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°è§£æ: diffã€å†…å®¹ã€ASTè§£æ"""
        try:
            # 1. diffæƒ…å ±ã‚’å–å¾—
            diff_info = self._fetch_file_diff(cl_number, file_path)
            
            # 2. ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—ï¼ˆå¤‰æ›´å¾Œï¼‰
            new_content = self._fetch_file_content(cl_number, file_path, revision_id)
            
            # 3. diffè¡Œç•ªå·ã‚’è§£æ
            changed_lines = self._parse_diff_lines(diff_info) if diff_info else []
            
            # 4. ASTè§£æï¼ˆæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼‰
            ast_analysis = {}
            if self.go_parser and new_content:
                ast_analysis = self._analyze_go_ast(new_content, changed_lines)
            
            return {
                'file_path': file_path,
                'status': file_info.get('status', ''),
                'lines_inserted': file_info.get('lines_inserted', 0),
                'lines_deleted': file_info.get('lines_deleted', 0),
                'changed_lines': changed_lines,
                'content_size': len(new_content) if new_content else 0,
                'ast_analysis': ast_analysis
            }
            
        except Exception as e:
            log_error(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_path} è©³ç´°è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _fetch_file_diff(self, cl_number: str, file_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®diffæƒ…å ±ã‚’å–å¾—"""
        encoded_path = file_path.replace('/', '%2F')
        endpoints = [
            f"{self.GERRIT_API_BASE}/changes/{cl_number}/revisions/current/files/{encoded_path}/diff",
            f"{self.GERRIT_API_BASE}/changes/go~{cl_number}/revisions/current/files/{encoded_path}/diff"
        ]
        
        for endpoint in endpoints:
            try:
                response = self.session.get(endpoint, timeout=30)
                if response.status_code == 200:
                    content = response.text
                    if content.startswith(")]}'"):
                        content = content[4:]
                    return content
            except Exception:
                continue
        
        return None
    
    def _parse_diff_lines(self, diff_content: str) -> List[Dict[str, Any]]:
        """diffå†…å®¹ã‹ã‚‰å¤‰æ›´è¡Œç•ªå·ã‚’è§£æ"""
        if not diff_content:
            log_warning("diff_content ãŒç©ºã§ã™")
            return []
        
        try:
            # Gerrit APIã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
            content = diff_content
            if content.startswith(")]}'"):
                content = content[4:]
            
            # JSONã¨ã—ã¦è§£æã‚’è©¦è¡Œ
            try:
                diff_data = json.loads(content)
                if 'content' in diff_data:
                    log_debug(f"Gerrit diffå½¢å¼ã§è§£æé–‹å§‹ã€ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(diff_data['content'])}")
                    result = self._parse_gerrit_diff_format(diff_data)
                    log_info(f"Gerrit diffè§£æå®Œäº†: {len(result)}è¡Œã®å¤‰æ›´ã‚’æ¤œå‡º")
                    return result
            except json.JSONDecodeError:
                pass
            
            # JSONå½¢å¼ã§ãªã„å ´åˆã€unified diffå½¢å¼ã¨ã—ã¦è§£æ
            log_debug("unified diffå½¢å¼ã¨ã—ã¦è§£æé–‹å§‹")
            result = self._parse_unified_diff_format(content)
            log_info(f"Unified diffè§£æå®Œäº†: {len(result)}è¡Œã®å¤‰æ›´ã‚’æ¤œå‡º")
            return result
            
        except Exception as e:
            log_error(f"diffè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            log_debug(f"diffå†…å®¹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰: {diff_content[:500]}")
            return []
    
    def _parse_gerrit_diff_format(self, diff_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Gerrit API ã® diff å½¢å¼ã‚’è§£æ"""
        changed_lines = []
        
        old_line_num = 1
        new_line_num = 1
        
        for diff_entry in diff_data.get('content', []):
            # å‰Šé™¤è¡Œ (only 'a' key)
            if 'a' in diff_entry and 'b' not in diff_entry:
                for line_text in diff_entry['a']:
                    changed_lines.append({
                        'type': 'deleted',
                        'old_line': old_line_num,
                        'content': line_text
                    })
                    old_line_num += 1
            
            # è¿½åŠ è¡Œ (only 'b' key)
            elif 'b' in diff_entry and 'a' not in diff_entry:
                for line_text in diff_entry['b']:
                    changed_lines.append({
                        'type': 'added',
                        'new_line': new_line_num,
                        'content': line_text
                    })
                    new_line_num += 1
            
            # å¤‰æ›´è¡Œ (both 'a' and 'b' keys)
            elif 'a' in diff_entry and 'b' in diff_entry:
                # å‰Šé™¤éƒ¨åˆ†
                for line_text in diff_entry['a']:
                    changed_lines.append({
                        'type': 'deleted',
                        'old_line': old_line_num,
                        'content': line_text
                    })
                    old_line_num += 1
                
                # è¿½åŠ éƒ¨åˆ†
                for line_text in diff_entry['b']:
                    changed_lines.append({
                        'type': 'added',
                        'new_line': new_line_num,
                        'content': line_text
                    })
                    new_line_num += 1
            
            # å¤‰æ›´ã•ã‚Œã¦ã„ãªã„è¡Œ ('ab' key)
            elif 'ab' in diff_entry:
                # å¤‰æ›´ã•ã‚Œã¦ã„ãªã„è¡Œã®åˆ†ã ã‘è¡Œç•ªå·ã‚’é€²ã‚ã‚‹
                line_count = len(diff_entry['ab'])
                old_line_num += line_count
                new_line_num += line_count
        
        log_debug(f"æŠ½å‡ºã•ã‚ŒãŸå¤‰æ›´è¡Œæ•°: {len(changed_lines)}")
        return changed_lines
    
    def _parse_unified_diff_format(self, diff_content: str) -> List[Dict[str, Any]]:
        """unified diffå½¢å¼ã‚’è§£æ"""
        changed_lines = []
        lines = diff_content.split('\n')
        
        old_line_num = 0
        new_line_num = 0
        
        for line in lines:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’è§£æ
            if line.startswith('@@'):
                # @@ -old_start,old_count +new_start,new_count @@
                match = re.search(r'@@\s*-(\d+)(?:,\d+)?\s*\+(\d+)(?:,\d+)?\s*@@', line)
                if match:
                    old_line_num = int(match.group(1))
                    new_line_num = int(match.group(2))
                continue
            
            # å‰Šé™¤è¡Œ
            if line.startswith('-') and not line.startswith('---'):
                changed_lines.append({
                    'type': 'deleted',
                    'old_line': old_line_num,
                    'content': line[1:]  # - ã‚’é™¤ã
                })
                old_line_num += 1
            
            # è¿½åŠ è¡Œ
            elif line.startswith('+') and not line.startswith('+++'):
                changed_lines.append({
                    'type': 'added',
                    'new_line': new_line_num,
                    'content': line[1:]  # + ã‚’é™¤ã
                })
                new_line_num += 1
            
            # å¤‰æ›´ãªã—è¡Œ
            elif line.startswith(' '):
                old_line_num += 1
                new_line_num += 1
        
        return changed_lines
    
    def _analyze_go_ast(self, content: str, changed_lines: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Goã‚³ãƒ¼ãƒ‰ã®ASTè§£æã‚’å®Ÿè¡Œã€‚å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ãƒ»ç„¡åé–¢æ•°ã‚’ç‰¹å®š"""
        if not self.go_parser:
            return {'error': 'tree-sitter parser not available'}

        try:
            tree = self.go_parser.parse(bytes(content, 'utf8'))
            root_node = tree.root_node

            # å¤‰æ›´å†…å®¹ã‚’æ•´ç†
            changes = []
            for change in changed_lines:
                if change['type'] == 'added':
                    changes.append({
                        'type': 'added',
                        'content': change['content'].strip(),
                        'line': change['new_line'],
                        'original_content': change['content']
                    })
                elif change['type'] == 'deleted':
                    changes.append({
                        'type': 'deleted',
                        'content': change['content'].strip(),
                        'line': change['old_line'],
                        'original_content': change['content']
                    })
            
            # å¤‰æ›´å†…å®¹ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆè¿‘æ¥ã™ã‚‹å¤‰æ›´ã‚’ã¾ã¨ã‚ã‚‹ï¼‰
            change_groups = []
            current_group = []
            
            for change in sorted(changes, key=lambda x: x['line']):
                if not current_group or abs(change['line'] - current_group[-1]['line']) <= 5:
                    current_group.append(change)
                else:
                    if current_group:
                        change_groups.append(current_group)
                    current_group = [change]
            
            if current_group:
                change_groups.append(current_group)

            # ã™ã¹ã¦ã®é–¢æ•°ãƒãƒ¼ãƒ‰ã‚’åé›†
            all_functions = []
            self._collect_all_functions(root_node, all_functions)

            # å¤‰æ›´ã•ã‚ŒãŸé–¢æ•°ã‚’ç‰¹å®š
            detected_functions = []
            for func_node in all_functions:
                start_line = func_node.start_point[0] + 1
                end_line = func_node.end_point[0] + 1
                
                # é–¢æ•°ã®å®Ÿéš›ã®æœ¬ä½“ã‚’å–å¾—ï¼ˆblockè¦ç´ ï¼‰
                actual_body_start = None
                actual_body_end = None
                for child in func_node.children:
                    if child.type == 'block':
                        actual_body_start = child.start_point[0] + 1
                        actual_body_end = child.end_point[0] + 1
                        break
                
                # æœ¬ä½“ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ã‚„é–¢æ•°å®£è¨€ãªã©ï¼‰
                is_declaration_only = actual_body_start is None
                if is_declaration_only:
                    # é–¢æ•°å®£è¨€ã®ã¿ã®å ´åˆã¯ã€å®£è¨€è¡Œã®ç¯„å›²ã‚’æœ¬ä½“ã¨ã—ã¦æ‰±ã†
                    actual_body_start = start_line
                    actual_body_end = end_line
                
                # ã“ã®é–¢æ•°ã«é–¢é€£ã™ã‚‹å¤‰æ›´ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ¢ã™
                func_changes = []
                overlapping_lines = []
                added_contents = []
                deleted_contents = []
                
                for group in change_groups:
                    # ã‚°ãƒ«ãƒ¼ãƒ—ã®é–‹å§‹è¡Œã¨çµ‚äº†è¡Œã‚’å–å¾—
                    group_start = min(c['line'] for c in group)
                    group_end = max(c['line'] for c in group)
                    
                    # å¤‰æ›´ã‚°ãƒ«ãƒ¼ãƒ—ãŒé–¢æ•°ã®ç¯„å›²å†…ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if ((start_line <= group_start <= end_line) or 
                        (start_line <= group_end <= end_line) or
                        (group_start <= start_line <= group_end)):
                        
                        # å¤‰æ›´ã®å†…å®¹ã‚’ç¢ºèª
                        real_changes = []
                        for change in group:
                            stripped_content = change['content']
                            original_content = change['original_content']
                            change_line = change['line']
                            
                            # é–¢æ•°ã®ç¯„å›²å¤–ã®å¤‰æ›´ã¯é™¤å¤–
                            if not (start_line <= change_line <= end_line):
                                continue
                            
                            # é–¢æ•°å®£è¨€ã®ã¿ã®å ´åˆã¯ã€å®£è¨€ã®å¤‰æ›´ã‚’æ¤œå‡ºå¯¾è±¡ã¨ã™ã‚‹
                            if is_declaration_only:
                                # é–¢æ•°å®£è¨€ã®å¤‰æ›´ã¯é‡è¦ãªå¤‰æ›´ã¨ã—ã¦æ‰±ã†
                                if stripped_content.startswith('func '):
                                    # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’é™¤å»ã—ã¦æ¯”è¼ƒ
                                    normalized_content = original_content.lstrip()
                                    
                                    # è¿½åŠ ãƒ»å‰Šé™¤ã•ã‚ŒãŸå†…å®¹ã‚’è¨˜éŒ²
                                    if change['type'] == 'added':
                                        added_contents.append(normalized_content)
                                    else:
                                        deleted_contents.append(normalized_content)
                                    
                                    real_changes.append(change)
                                    overlapping_lines.append(change_line)
                                continue
                            
                            # é€šå¸¸ã®é–¢æ•°ï¼ˆæœ¬ä½“ãŒã‚ã‚‹å ´åˆï¼‰ã®å‡¦ç†
                            # é–¢æ•°å®£è¨€ã‚„é–‰ã˜æ‹¬å¼§ã€ç©ºè¡Œã¯é™¤å¤–
                            if (not stripped_content or 
                                stripped_content == '}' or 
                                (stripped_content.startswith('func ') and change_line == start_line)):
                                continue
                            
                            # é–¢æ•°ã®æœ¬ä½“ä»¥å¤–ã®å¤‰æ›´ï¼ˆå®£è¨€éƒ¨åˆ†ã®å¤‰æ›´ãªã©ï¼‰ã‚‚é™¤å¤–
                            if actual_body_start and change_line < actual_body_start:
                                # é–¢æ•°ã®å®£è¨€éƒ¨åˆ†ã®å¤‰æ›´ã¯é™¤å¤–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰æ›´ãªã©ï¼‰
                                continue
                            
                            # é–¢æ•°ã®çµ‚äº†è¡Œï¼ˆé–‰ã˜æ‹¬å¼§ï¼‰ã®å¤‰æ›´ã‚‚é™¤å¤–
                            if actual_body_end and change_line >= actual_body_end:
                                continue
                            
                            # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’é™¤å»ã—ã¦æ¯”è¼ƒ
                            normalized_content = original_content.lstrip()
                            
                            # è¿½åŠ ãƒ»å‰Šé™¤ã•ã‚ŒãŸå†…å®¹ã‚’è¨˜éŒ²
                            if change['type'] == 'added':
                                added_contents.append(normalized_content)
                            else:
                                deleted_contents.append(normalized_content)
                            
                            real_changes.append(change)
                            overlapping_lines.append(change_line)
                        
                        if real_changes:
                            func_changes.extend(real_changes)
                
                # é–¢æ•°ã®å†…å®¹ãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
                has_real_changes = False
                if func_changes:
                    # é–¢æ•°å®£è¨€ã®ã¿ã®å ´åˆã¯ã€ã‚·ã‚°ãƒãƒãƒ£ã®å¤‰æ›´ã‚’æ¤œå‡º
                    if is_declaration_only:
                        # è¿½åŠ ã•ã‚ŒãŸè¡Œã¨å‰Šé™¤ã•ã‚ŒãŸè¡Œã‚’æ¯”è¼ƒ
                        added_set = set(added_contents)
                        deleted_set = set(deleted_contents)
                        
                        # é–¢æ•°å®£è¨€ã®å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        if len(added_set) > 0 and len(deleted_set) > 0:
                            # æ­£è¦åŒ–ã—ã¦æ¯”è¼ƒ
                            normalized_added = set(line.strip() for line in added_set)
                            normalized_deleted = set(line.strip() for line in deleted_set)
                            
                            # ã‚·ã‚°ãƒãƒãƒ£ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹å ´åˆ
                            if normalized_added != normalized_deleted:
                                has_real_changes = True
                        elif len(added_set) > 0 or len(deleted_set) > 0:
                            # è¿½åŠ ã®ã¿ã¾ãŸã¯å‰Šé™¤ã®ã¿ã®å ´åˆã‚‚å¤‰æ›´ã¨ã¿ãªã™
                            has_real_changes = True
                    else:
                        # é€šå¸¸ã®é–¢æ•°ã®å ´åˆã®å‡¦ç†ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                        # è¿½åŠ ã•ã‚ŒãŸè¡Œã¨å‰Šé™¤ã•ã‚ŒãŸè¡Œã‚’æ¯”è¼ƒ
                        added_set = set(added_contents)
                        deleted_set = set(deleted_contents)
                        
                        # é–¢æ•°ã®ç§»å‹•ã‚’æ¤œå‡º
                        is_function_moved = False
                        if len(added_set) == len(deleted_set) and len(added_set) > 0:
                            # å†…å®¹ãŒåŒã˜ã§ã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã ã‘ãŒç•°ãªã‚‹å ´åˆã¯ç§»å‹•ã¨ã¿ãªã™
                            normalized_added = set(line.strip() for line in added_set)
                            normalized_deleted = set(line.strip() for line in deleted_set)
                            
                            # é–¢æ•°ã®å®£è¨€è¡Œã¨çµ‚äº†è¡Œã‚’é™¤å¤–ã—ã¦æ¯”è¼ƒ
                            filtered_added = set()
                            filtered_deleted = set()
                            
                            for line in normalized_added:
                                if not (line.startswith('func ') or line == '}' or not line):
                                    filtered_added.add(line)
                            
                            for line in normalized_deleted:
                                if not (line.startswith('func ') or line == '}' or not line):
                                    filtered_deleted.add(line)
                            
                            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸå†…å®¹ã‚’æ¯”è¼ƒ
                            if len(filtered_added) > 0 and filtered_added == filtered_deleted:
                                is_function_moved = True
                        
                        # é–¢æ•°ã®å†…å®¹ãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
                        if not is_function_moved and len(added_set) > 0 and len(deleted_set) > 0:
                            # é–¢æ•°ã®å®£è¨€è¡Œã¨çµ‚äº†è¡Œã®å¤‰æ›´ã¯ç„¡è¦–
                            filtered_added = set()
                            filtered_deleted = set()
                            
                            for content in added_set:
                                content = content.strip()
                                if not (content.startswith('func ') or content == '}' or not content):
                                    filtered_added.add(content)
                            
                            for content in deleted_set:
                                content = content.strip()
                                if not (content.startswith('func ') or content == '}' or not content):
                                    filtered_deleted.add(content)
                            
                            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸå†…å®¹ã‚’æ¯”è¼ƒ
                            if filtered_added != filtered_deleted:
                                # å®Ÿéš›ã®å†…å®¹å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                                normalized_added = set(line.strip() for line in filtered_added)
                                normalized_deleted = set(line.strip() for line in filtered_deleted)
                                
                                # é–¢æ•°ã®æœ¬ä½“ã®å†…å®¹ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                                if normalized_added != normalized_deleted:
                                    # é–¢æ•°ã®æœ¬ä½“ãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿
                                    has_real_changes = True
                        elif not is_function_moved and (len(added_set) > 0 or len(deleted_set) > 0):
                            # è¿½åŠ ã®ã¿ã¾ãŸã¯å‰Šé™¤ã®ã¿ã®å ´åˆã‚‚å¤‰æ›´ã¨ã¿ãªã™
                            has_real_changes = True
                
                if has_real_changes:
                    # å®Ÿéš›ã®å†…å®¹å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿é–¢æ•°ã‚’è¿½åŠ 
                    func_name = self._extract_function_name(func_node)
                    full_name = self._extract_full_function_name(func_node)
                    selection_reason = 'function_declaration_change' if is_declaration_only else 'actual_content_change'
                    detected_functions.append({
                        'function_name': func_name,
                        'full_name': full_name,
                        'start_line': start_line,
                        'end_line': end_line,
                        'body_start': actual_body_start,
                        'body_end': actual_body_end,
                        'is_declaration_only': is_declaration_only,
                        'overlapping_lines': sorted(list(set(overlapping_lines))),
                        'confidence': 'high',
                        'has_actual_changes': has_real_changes,
                        'selection_reason': selection_reason
                    })

            return {'detected_functions': detected_functions}

        except Exception as e:
            log_error(f"ASTè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}

    def _calculate_node_depth(self, node):
        """ãƒãƒ¼ãƒ‰ã®æ·±ã•ï¼ˆãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ï¼‰ã‚’è¨ˆç®—"""
        depth = 0
        current = node
        while current.parent:
            if current.parent.type in ("function_declaration", "method_declaration"):
                depth += 1
            current = current.parent
        return depth
    
    def _collect_all_functions(self, node, all_functions):
        """å†å¸°çš„ã«é–¢æ•°ãƒãƒ¼ãƒ‰ã‚’åé›†ï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
        # é€šå¸¸ã®é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰
        if node.type in ("function_declaration", "method_declaration"):
            all_functions.append(node)
        
        # å¤‰æ•°å®£è¨€ã‹ã‚‰åå‰ä»˜ãé–¢æ•°ãƒªãƒ†ãƒ©ãƒ«ã‚’æ¤œå‡º
        if node.type == "var_declaration":
            for child in node.children:
                if child.type == "var_spec":
                    var_name = None
                    function_literal = None
                    for vchild in child.children:
                        if vchild.type == "identifier":
                            var_name = vchild.text.decode('utf-8') if isinstance(vchild.text, bytes) else vchild.text
                        elif vchild.type == "expression_list":
                            for expr_child in vchild.children:
                                if expr_child.type == "function_literal":
                                    function_literal = expr_child
                                    break
                    if var_name and function_literal:
                        all_functions.append({
                            'type': 'named_function_literal',
                            'name': var_name,
                            'node': function_literal,
                            'start_point': function_literal.start_point,
                            'end_point': function_literal.end_point
                        })
        
        # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰
        if node.type == "type_declaration":
            for child in node.children:
                if child.type == "type_spec":
                    for grandchild in child.children:
                        if grandchild.type == "interface_type":
                            for method in grandchild.children:
                                if method.type == "method_spec":
                                    all_functions.append(method)
        
        # å­ãƒãƒ¼ãƒ‰ã‚’å†å¸°çš„ã«å‡¦ç†
        for child in node.children:
            self._collect_all_functions(child, all_functions)

    def _extract_function_name(self, func_node):
        """é–¢æ•°ãƒãƒ¼ãƒ‰ã‹ã‚‰é–¢æ•°åã‚’æŠ½å‡ºï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
        if isinstance(func_node, dict) and func_node.get('type') == 'named_function_literal':
            return func_node.get('name', 'unknown')
        if not isinstance(func_node, dict) and hasattr(func_node, 'type') and func_node.type == 'method_spec':
            for child in getattr(func_node, 'children', []):
                if child.type in ['identifier', 'field_identifier']:
                    name = child.text
                    if isinstance(name, bytes):
                        name = name.decode('utf-8')
                    return name.strip()
        if not isinstance(func_node, dict) and hasattr(func_node, 'type') and func_node.type == 'function_declaration':
            for child in getattr(func_node, 'children', []):
                if child.type == 'identifier':
                    name = child.text
                    if isinstance(name, bytes):
                        name = name.decode('utf-8')
                    return name.strip()
        elif not isinstance(func_node, dict) and hasattr(func_node, 'type') and func_node.type == 'method_declaration':
            found_receiver = False
            method_name = None
            for child in getattr(func_node, 'children', []):
                if child.type == 'parameter_list' and not found_receiver:
                    found_receiver = True
                    continue
                elif child.type in ['identifier', 'field_identifier'] and found_receiver:
                    name = child.text
                    if isinstance(name, bytes):
                        name = name.decode('utf-8')
                    method_name = name.strip()
                    break
            if method_name:
                return method_name
        return "unknown"

    def _extract_full_function_name(self, func_node):
        """é–¢æ•°ãƒãƒ¼ãƒ‰ã‹ã‚‰ãƒ•ãƒ«ãƒãƒ¼ãƒ ã‚’æŠ½å‡ºï¼ˆãƒ¡ã‚½ãƒƒãƒ‰ã®å ´åˆã¯ãƒ¬ã‚·ãƒ¼ãƒãƒ¼æƒ…å ±ã‚’å«ã‚€ï¼‰"""
        if func_node.type == 'function_declaration':
            # é€šå¸¸ã®é–¢æ•°å®£è¨€ã®å ´åˆ
            return self._extract_function_name(func_node)
            
        elif func_node.type == 'method_declaration':
            # ãƒ¡ã‚½ãƒƒãƒ‰å®£è¨€ã®å ´åˆï¼ˆãƒ¬ã‚·ãƒ¼ãƒãƒ¼ãŒã‚ã‚‹ï¼‰
            # æ§‹é€ : func (receiver) methodName(params) returnType { body }
            receiver_info = ""
            method_name = ""
            
            found_receiver = False
            for child in func_node.children:
                if child.type == 'parameter_list' and not found_receiver:
                    # æœ€åˆã®parameter_listã¯ãƒ¬ã‚·ãƒ¼ãƒãƒ¼
                    found_receiver = True
                    # ãƒ¬ã‚·ãƒ¼ãƒãƒ¼æƒ…å ±ã‚’æŠ½å‡º
                    receiver_parts = []
                    for receiver_child in child.children:
                        if receiver_child.type in ['identifier', 'pointer_type', 'type_identifier']:
                            text = receiver_child.text
                            if isinstance(text, bytes):
                                text = text.decode('utf-8')
                            receiver_parts.append(text.strip())
                    if receiver_parts:
                        # ãƒ¬ã‚·ãƒ¼ãƒãƒ¼åã¨å‹ã‚’çµåˆ
                        if len(receiver_parts) >= 2:
                            receiver_info = f"({receiver_parts[0]} {receiver_parts[1]})"
                        else:
                            receiver_info = f"({receiver_parts[0]})"
                    continue
                elif child.type in ['identifier', 'field_identifier'] and found_receiver:
                    # ãƒ¬ã‚·ãƒ¼ãƒãƒ¼ã®å¾Œã®identifierã¾ãŸã¯field_identifierãŒãƒ¡ã‚½ãƒƒãƒ‰å
                    method_name = child.text
                    if isinstance(method_name, bytes):
                        method_name = method_name.decode('utf-8')
                    method_name = method_name.strip()
                    break
                    
            if receiver_info and method_name:
                return f"{receiver_info}.{method_name}"
            elif method_name:
                return method_name
        
        return "unknown"

    def _get_line_start_offsets(self, content: str) -> List[int]:
        """å„è¡Œã®é–‹å§‹byte offsetãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼ˆ0-indexedï¼‰"""
        offsets = []
        offset = 0
        for line in content.splitlines(keepends=True):
            offsets.append(offset)
            offset += len(line.encode('utf-8'))
        return offsets

    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    def _read_file(self, file_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            log_error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path}, {str(e)}")
            return None
    
    def _extract_cl_numbers(self, content: str) -> List[str]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰CLç•ªå·ã‚’æŠ½å‡º"""
        patterns = [
            r'https://golang\.org/cl/(\d+)',
            r'https://go\.dev/cl/(\d+)',
            r'https://go-review\.googlesource\.com/c/go/\+/?(\d+)',
            r'Change https://golang\.org/cl/(\d+)',
            r'Change https://go\.dev/cl/(\d+)',
            r'CL\s+(\d+)',
            r'cl/(\d+)',
        ]
        
        cl_numbers = set()
        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            cl_numbers.update(matches)
        
        return sorted(list(cl_numbers))
    
    def _fetch_cl_info(self, cl_number: str) -> Optional[Dict[str, Any]]:
        """CLåŸºæœ¬æƒ…å ±ã‚’å–å¾—"""
        endpoints = [
            f"{self.GERRIT_API_BASE}/changes/{cl_number}?o=CURRENT_REVISION&o=CURRENT_COMMIT",
            f"{self.GERRIT_API_BASE}/changes/go~{cl_number}?o=CURRENT_REVISION&o=CURRENT_COMMIT"
        ]
        
        for endpoint in endpoints:
            try:
                response = self.session.get(endpoint, timeout=30)
                if response.status_code == 200:
                    content = response.text
                    if content.startswith(")]}'"):
                        content = content[4:]
                    return json.loads(content)
            except Exception:
                continue
        
        return None
    
    def _fetch_file_list(self, cl_number: str) -> Optional[Dict[str, Any]]:
        """å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        endpoints = [
            f"{self.GERRIT_API_BASE}/changes/{cl_number}/revisions/current/files",
            f"{self.GERRIT_API_BASE}/changes/go~{cl_number}/revisions/current/files"
        ]
        
        for endpoint in endpoints:
            try:
                response = self.session.get(endpoint, timeout=30)
                if response.status_code == 200:
                    content = response.text
                    if content.startswith(")]}'"):
                        content = content[4:]
                    return json.loads(content)
            except Exception:
                continue
        
        return None
    
    def _fetch_file_content(self, cl_number: str, file_path: str, revision_id: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—"""
        encoded_path = file_path.replace('/', '%2F')
        endpoints = [
            f"{self.GERRIT_API_BASE}/changes/{cl_number}/revisions/{revision_id}/files/{encoded_path}/content",
            f"{self.GERRIT_API_BASE}/changes/go~{cl_number}/revisions/{revision_id}/files/{encoded_path}/content"
        ]
        
        for endpoint in endpoints:
            try:
                response = self.session.get(endpoint, timeout=30)
                if response.status_code == 200:
                    content = response.text
                    try:
                        # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
                        decoded_content = base64.b64decode(content).decode('utf-8')
                        return decoded_content
                    except Exception:
                        # Base64ã§ãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                        return content
            except Exception:
                continue
        
        return None

def print_analysis_summary(result):
    """è§£æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    print("\n=== æ‹¡å¼µè§£æçµæœ ===")
    print(f"ææ¡ˆãƒ•ã‚¡ã‚¤ãƒ«: {result['proposal_file']}")
    print(f"CLç•ªå·: {result['cl_numbers']}")
    print(f"è§£æã—ãŸCLæ•°: {result['total_cls_analyzed']}")
    print(f"tree-sitteræœ‰åŠ¹: {result.get('tree_sitter_enabled', False)}")
    print()

    for cl in result['cl_analyses']:
        print(f"--- CL {cl['cl_number']} ---")
        print(f"ä»¶å: {cl['subject']}")
        print(f"Goãƒ•ã‚¡ã‚¤ãƒ«è§£ææ•°: {cl['go_files_analyzed']}")
        
        for file in cl['files']:
            print(f"  ğŸ“„ {file['file_path']}")
            print(f"     çŠ¶æ…‹: {file.get('status', '')}")
            print(f"     å¤‰æ›´è¡Œæ•°: +{file['lines_inserted']} -{file['lines_deleted']}")
            print(f"     å·®åˆ†è¡Œæ•°: {len(file['changed_lines'])}")
            
            # æ¤œå‡ºã•ã‚ŒãŸé–¢æ•°ã®æƒ…å ±ã‚’è¡¨ç¤º
            if 'ast_analysis' in file and 'detected_functions' in file['ast_analysis']:
                functions = file['ast_analysis']['detected_functions']
                if functions:
                    print("     æ¤œå‡ºã•ã‚ŒãŸé–¢æ•°:")
                    for func in functions:
                        # é–¢æ•°åã®è¡¨ç¤ºï¼ˆfull_nameãŒã‚ã‚‹å ´åˆã¯ãã¡ã‚‰ã‚’ä½¿ç”¨ï¼‰
                        func_name = func.get('full_name', func.get('function_name', 'unknown'))
                        print(f"       - {func_name} (è¡Œ: {func['start_line']}-{func['end_line']})")
                        if func.get('has_actual_changes', False):
                            print(f"         å¤‰æ›´è¡Œ: {func['overlapping_lines']}")
            print()

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='æ‹¡å¼µCLã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼: å·®åˆ†è¡Œã¨ASTè§£æ')
    parser.add_argument('proposal_file', help='ææ¡ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--output', '-o', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆJSONã§ä¿å­˜ï¼‰')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°ãƒ­ã‚°')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # æ‹¡å¼µè§£æå®Ÿè¡Œ
    analyzer = EnhancedCLAnalyzer()
    result = analyzer.analyze_proposal(args.proposal_file)
    
    # çµæœè¡¨ç¤º
    print_analysis_summary(result)
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {args.output}")
    
if __name__ == '__main__':
    main()
