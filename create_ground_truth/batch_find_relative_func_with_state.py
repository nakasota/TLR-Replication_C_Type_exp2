#!/usr/bin/env python3
"""
CLçŠ¶æ…‹ã‚’è€ƒæ…®ã—ãŸãƒãƒƒãƒé–¢æ•°è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
MERGEDçŠ¶æ…‹ã®CLã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¦é–¢æ•°è§£æã‚’å®Ÿè¡Œã™ã‚‹
å¤‰æ›´å†…å®¹ã®è©³ç´°æƒ…å ±ä»˜ã
"""

import os
import glob
import json
import sys
from pathlib import Path
from find_relative_func import EnhancedCLAnalyzer
from content_validator import ContentValidator
from repo_loader import GoRepoLoader
from tqdm import tqdm
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def main():
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    proposals_dir = Path("../data/preprocess/accepted_proposals")
    output_json = Path("../data/ground_truth/accepted_proposals_func_analysis_merged_validated.json")
    repo_structure_path = Path("../data/ground_truth/go_repo_structure.json")

    # .mdãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦å–å¾—
    md_files = sorted(proposals_dir.glob("*.md"))
    print(f"è§£æå¯¾è±¡: {len(md_files)}ä»¶ã®mdãƒ•ã‚¡ã‚¤ãƒ«")

    # ãƒªãƒã‚¸ãƒˆãƒªãƒ­ãƒ¼ãƒ€ãƒ¼ã¨å¤‰æ›´å†…å®¹æ¤œè¨¼å™¨ã‚’åˆæœŸåŒ–
    print("ğŸ”§ ãƒªãƒã‚¸ãƒˆãƒªãƒ­ãƒ¼ãƒ€ãƒ¼ã¨å¤‰æ›´å†…å®¹æ¤œè¨¼å™¨ã‚’åˆæœŸåŒ–ä¸­...")
    repo_loader = GoRepoLoader(str(repo_structure_path))
    content_validator = ContentValidator(repo_loader)

    analyzer = EnhancedCLAnalyzer()
    all_results = []
    failed_files = []
    merged_count = 0
    non_merged_count = 0
    status_counts = {}
    content_analysis_stats = {
        'functions_with_content_analysis': 0,
        'content_validation_errors': 0
    }

    # tqdmã‚’ä½¿ç”¨ã—ã¦é€²æ—è¡¨ç¤º
    with tqdm(md_files, desc="ææ¡ˆãƒ•ã‚¡ã‚¤ãƒ«è§£æä¸­", unit="file", 
              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {postfix}') as pbar:
        for md_file in pbar:
            try:
                # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«åã¨çµ±è¨ˆã‚’é€²æ—ãƒãƒ¼ã«è¡¨ç¤º
                pbar.set_postfix_str(f"{md_file.name} | MERGED: {merged_count}, ææ¡ˆ: {len(all_results)}")
                result = analyzer.analyze_proposal(str(md_file))
                
                # CLã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                filtered_cl_analyses = []
                for cl_analysis in result.get('cl_analyses', []):
                    cl_status = cl_analysis.get('status', '').upper()
                    
                    # çµ±è¨ˆç”¨ã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    status_counts[cl_status] = status_counts.get(cl_status, 0) + 1
                    
                    # MERGEDçŠ¶æ…‹ã®ã‚‚ã®ã®ã¿ã‚’æ¡ç”¨
                    if cl_status == 'MERGED':
                        # MERGEDçŠ¶æ…‹ã®CLã«å¯¾ã—ã¦å¤‰æ›´å†…å®¹åˆ†æã‚’è¿½åŠ 
                        enhanced_cl_analysis = cl_analysis.copy()
                        
                        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®é–¢æ•°ã«å¯¾ã—ã¦å¤‰æ›´å†…å®¹åˆ†æã‚’å®Ÿè¡Œ
                        enhanced_files = []
                        for file_data in cl_analysis.get('files', []):
                            enhanced_file_data = file_data.copy()
                            
                            # ASTè§£æçµæœãŒã‚ã‚‹å ´åˆã€å¤‰æ›´å†…å®¹åˆ†æã‚’è¿½åŠ 
                            ast_analysis = file_data.get('ast_analysis', {})
                            if 'detected_functions' in ast_analysis:
                                enhanced_functions = []
                                
                                for func in ast_analysis['detected_functions']:
                                    enhanced_func = func.copy()
                                    
                                    try:
                                        # å¤‰æ›´å†…å®¹ã®è¿½åŠ åˆ†æ
                                        func_name = func.get('function_name')
                                        file_path = file_data.get('file_path')
                                        changed_lines = file_data.get('changed_lines', [])
                                        
                                        if func_name and file_path and changed_lines:
                                            # é–¢æ•°ç¯„å›²å†…ã®å¤‰æ›´è¡Œã‚’æŠ½å‡º
                                            func_start = func.get('start_line', 1)
                                            func_end = func.get('end_line', 1)
                                            
                                            func_changes = [
                                                line for line in changed_lines
                                                if func_start <= line.get('new_line', 0) <= func_end or
                                                   func_start <= line.get('old_line', 0) <= func_end
                                            ]
                                            
                                            enhanced_func['function_changes'] = {
                                                'changes_in_function': len(func_changes),
                                                'added_lines': [
                                                    line.get('content', '') 
                                                    for line in func_changes 
                                                    if line.get('type') == 'added'
                                                ]
                                            }
                                            
                                            content_analysis_stats['functions_with_content_analysis'] += 1
                                        
                                    except Exception as e:
                                        logging.error(f"Content analysis error for {func_name}: {str(e)}")
                                        content_analysis_stats['content_validation_errors'] += 1
                                    
                                    enhanced_functions.append(enhanced_func)
                                
                                # å¼·åŒ–ã•ã‚ŒãŸASTè§£æçµæœã§ç½®ãæ›ãˆ
                                enhanced_ast_analysis = ast_analysis.copy()
                                enhanced_ast_analysis['detected_functions'] = enhanced_functions
                                enhanced_file_data['ast_analysis'] = enhanced_ast_analysis
                            
                            enhanced_files.append(enhanced_file_data)
                        
                        enhanced_cl_analysis['files'] = enhanced_files
                        filtered_cl_analyses.append(enhanced_cl_analysis)
                        merged_count += 1
                    else:
                        non_merged_count += 1
                
                # MERGEDçŠ¶æ…‹ã®CLãŒã‚ã‚‹å ´åˆã®ã¿çµæœã«è¿½åŠ 
                if filtered_cl_analyses:
                    filtered_result = result.copy()
                    filtered_result['cl_analyses'] = filtered_cl_analyses
                    all_results.append(filtered_result)
                    
            except Exception as e:
                print(f"[ERROR] {md_file}: {e}")
                failed_files.append({"file": str(md_file), "error": str(e)})

    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print(f"\nğŸ“Š CLçŠ¶æ…‹çµ±è¨ˆ:")
    print(f"â”œâ”€ MERGEDçŠ¶æ…‹ã®CL: {merged_count}ä»¶")
    print(f"â”œâ”€ éMERGEDçŠ¶æ…‹ã®CL: {non_merged_count}ä»¶")
    print(f"â””â”€ MERGEDçŠ¶æ…‹ã‚’å«ã‚€ææ¡ˆ: {len(all_results)}ä»¶")
    
    print(f"\nğŸ“‹ çŠ¶æ…‹åˆ¥è©³ç´°:")
    for status, count in sorted(status_counts.items()):
        print(f"â”œâ”€ {status}: {count}ä»¶")
    
    print(f"\nğŸ” å¤‰æ›´å†…å®¹åˆ†æçµ±è¨ˆ:")
    print(f"â”œâ”€ å¤‰æ›´å†…å®¹åˆ†ææ¸ˆã¿é–¢æ•°: {content_analysis_stats['functions_with_content_analysis']}ä»¶")
    print(f"â””â”€ åˆ†æã‚¨ãƒ©ãƒ¼: {content_analysis_stats['content_validation_errors']}ä»¶")

    # çµæœã‚’ä¿å­˜
    output_json.parent.mkdir(parents=True, exist_ok=True)
    with open(output_json, "w", encoding="utf-8") as f:
        json.dump({
            "results": all_results,
            "failed_files": failed_files,
            "statistics": {
                "total_proposals_analyzed": len(md_files),
                "proposals_with_merged_cls": len(all_results),
                "merged_cls_count": merged_count,
                "non_merged_cls_count": non_merged_count,
                "status_breakdown": status_counts,
                "content_analysis_stats": content_analysis_stats
            }
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ MERGEDçŠ¶æ…‹ã®CLã®ã¿ã‚’å«ã‚€çµæœï¼ˆå¤‰æ›´å†…å®¹æ¤œè¨¼ä»˜ãï¼‰ã‚’ä¿å­˜: {output_json}")
    print(f"å¤±æ•—: {len(failed_files)}ä»¶")

if __name__ == "__main__":
    main()
